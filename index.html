
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>FrankLin&#39;s World</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="FrankLin's World">
<meta property="og:url" content="http://linrunzhang.github.io/index.html">
<meta property="og:site_name" content="FrankLin's World">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FrankLin's World">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="FrankLin&#39;s World" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
</head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">FrankLin&#39;s World</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="linrunzhang.github.io">
        </form>
      </div>
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main">
  
    <article id="post-hadoop-读写分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/26/hadoop-读写分析/" class="article-date">
  <time datetime="2015-11-26T05:32:27.000Z" itemprop="datePublished">2015-11-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/26/hadoop-读写分析/">hadoop 读写分析</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、文件的打开</p>
<p><img src="https://github.com/linrunzhang/linrunzhang.github.io/blob/master/resource/hadoop_read.png" alt="Hadoop Read"></p>
<p><img src="https://github.com/linrunzhang/linrunzhang.github.io/blob/master/resource/hadoop_write.png" alt="Hadoop Write"> </p>
<p>1.1、客户端<br>HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：</p>
<pre><code><span class="keyword">public</span> FSDataInputStream <span class="built_in">open</span>(Path f, <span class="built_in">int</span> bufferSize) <span class="keyword">throws</span> IOException {
<span class="keyword">return</span> <span class="keyword">new</span> DFSClient.DFSDataInputStream(
dfs.<span class="built_in">open</span>(getPathName(f), bufferSize, verifyChecksum, statistics));
}
</code></pre><p>其中dfs为DistributedFileSystem的成员变量DFSClient，其open函数被调用，其中创建一个DFSInputStream(src, buffersize, verifyChecksum)并返回。</p>
<p>在DFSInputStream的构造函数中，openInfo函数被调用，其主要从namenode中得到要打开的文件所对应的blocks的信息，实现如下：</p>
<pre><code>    <span class="keyword">synchronized</span> <span class="function"><span class="keyword">void</span> <span class="title">openInfo</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>{

    LocatedBlocks newInfo = callGetBlockLocations(namenode, src, <span class="number">0</span>, prefetchSize);
    <span class="keyword">this</span>.locatedBlocks = newInfo;
    <span class="keyword">this</span>.currentNode = <span class="keyword">null</span>;
    }

<span class="keyword">private</span> <span class="keyword">static</span> <span class="function">LocatedBlocks <span class="title">callGetBlockLocations</span><span class="params">(ClientProtocol namenode,

String src, <span class="keyword">long</span> start, <span class="keyword">long</span> length)</span> <span class="keyword">throws</span> IOException </span>{

<span class="function"><span class="keyword">return</span> namenode.<span class="title">getBlockLocations</span><span class="params">(src, start, length)</span></span>;

}
</code></pre><p>LocatedBlocks主要包含一个链表的List<locatedblock> blocks，其中每个LocatedBlock包含如下信息：</locatedblock></p>
<p>Block b：此block的信息<br>long offset：此block在文件中的偏移量<br>DatanodeInfo[] locs：此block位于哪些DataNode上<br>上面namenode.getBlockLocations是一个RPC调用，最终调用NameNode类的getBlockLocations函数。</p>
<p>1.2、NameNode<br>NameNode.getBlockLocations实现如下：</p>
<pre><code><span class="keyword">public</span> <span class="function">LocatedBlocks   <span class="title">getBlockLocations</span><span class="params">(String src,

                                    <span class="keyword">long</span> offset,

                                    <span class="keyword">long</span> length)</span> <span class="keyword">throws</span> IOException </span>{

<span class="keyword">return</span> namesystem.getBlockLocations(getClientMachine(),

                                  src, offset, length);
</code></pre><p>}</p>
<p>namesystem是NameNode一个成员变量，其类型为FSNamesystem，保存的是NameNode的name space树，其中一个重要的成员变量为FSDirectory dir。</p>
<p>FSDirectory和Lucene中的FSDirectory没有任何关系，其主要包括FSImage fsImage，用于读写硬盘上的fsimage文件，FSImage类有成员变量FSEditLog editLog，用于读写硬盘上的edit文件，这两个文件的关系在上一篇文章中已经解释过。</p>
<p>FSDirectory还有一个重要的成员变量INodeDirectoryWithQuota rootDir，INodeDirectoryWithQuota的父类为INodeDirectory，实现如下：</p>
<pre><code>public <span class="class"><span class="keyword">class</span> <span class="title">INodeDirectory</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">INode</span> {</span>

 ……

<span class="keyword">private</span> <span class="type">List</span>&lt;<span class="type">INode</span>&gt; children;

 ……

｝
</code></pre><p>由此可见INodeDirectory本身是一个INode，其中包含一个链表的INode，此链表中，如果仍为文件夹，则是类型INodeDirectory，如果是文件，则是类型INodeFile，INodeFile中有成员变量BlockInfo blocks[]，是此文件包含的block的信息。显然这是一棵树形的结构。</p>
<p>FSNamesystem.getBlockLocations函数如下：</p>
<pre><code><span class="keyword">public</span> <span class="function">LocatedBlocks <span class="title">getBlockLocations</span><span class="params">(String src, <span class="keyword">long</span> offset, <span class="keyword">long</span> length,

<span class="keyword">boolean</span> doAccessTime)</span> <span class="keyword">throws</span> IOException </span>{

<span class="keyword">final</span> LocatedBlocks ret = getBlockLocationsInternal(src, dir.getFileINode(src),

                 offset, length, Integer.MAX_VALUE, doAccessTime); 
<span class="keyword">return</span> ret;

}
</code></pre><p>dir.getFileINode(src)通过路径名从文件系统树中找到INodeFile，其中保存的是要打开的文件的INode的信息。</p>
<p>getBlockLocationsInternal的实现如下：</p>
<pre><code><span class="function"><span class="keyword">private</span> synchronized LocatedBlocks <span class="title">getBlockLocationsInternal</span><span class="params">(String src,

                                                 INodeFile inode,

                                                 <span class="keyword">long</span> offset,

                                                 <span class="keyword">long</span> length,

                                                 <span class="keyword">int</span> nrBlocksToReturn,

                                                 boolean doAccessTime)</span>

                                                 throws IOException </span>{

  <span class="comment">//得到此文件的block信息</span>

  Block[] blocks = inode.getBlocks();

  List&lt;LocatedBlock&gt; results = <span class="keyword">new</span> ArrayList&lt;LocatedBlock&gt;(blocks.length);

  <span class="comment">//计算从offset开始，长度为length所涉及的blocks</span>

  <span class="keyword">int</span> curBlk = <span class="number">0</span>;

  <span class="keyword">long</span> curPos = <span class="number">0</span>, blkSize = <span class="number">0</span>;

  <span class="keyword">int</span> nrBlocks = (blocks[<span class="number">0</span>].getNumBytes() == <span class="number">0</span>) ? <span class="number">0</span> : blocks.length;

  <span class="keyword">for</span> (curBlk = <span class="number">0</span>; curBlk &lt; nrBlocks; curBlk++) {

    blkSize = blocks[curBlk].getNumBytes();

    <span class="keyword">if</span> (curPos + blkSize &gt; offset) {

      <span class="comment">//当offset在curPos和curPos + blkSize之间的时候，curBlk指向offset所在的block</span>

      <span class="keyword">break</span>;

    }

    curPos += blkSize;

  }

  <span class="keyword">long</span> endOff = offset + length;
</code></pre><p>  //循环，依次遍历从curBlk开始的每个block，直到当前位置curPos越过endOff</p>
<pre><code><span class="label">do</span> {

<span class="label">int</span> numNodes = <span class="keyword">blocksMap.numNodes(blocks[curBlk]);
</span>
<span class="label">int</span> numCorruptNodes = countNodes(<span class="keyword">blocks[curBlk]).corruptReplicas();
</span>
<span class="label">int</span> numCorruptReplicas = corruptReplicas.numCorruptReplicas(<span class="keyword">blocks[curBlk]);
</span>
<span class="keyword">boolean </span><span class="keyword">blockCorrupt </span>= (numCorruptNodes == numNodes)<span class="comment">;</span>

<span class="label">int</span> numMachineSet = <span class="keyword">blockCorrupt </span>? numNodes :

                      (numNodes - numCorruptNodes)<span class="comment">;</span>

//依次找到此<span class="keyword">block所对应的datanode，将其中没有损坏的放入machineSet中
</span>
<span class="label">DatanodeDescriptor</span>[] machineSet = new DatanodeDescriptor[numMachineSet]<span class="comment">;</span>

<span class="label">if</span> (numMachineSet &gt; <span class="number">0</span>) {

  numNodes = <span class="number">0</span><span class="comment">;</span>

  for(<span class="keyword">Iterator&lt;DatanodeDescriptor&gt; </span><span class="keyword">it </span>=

      <span class="keyword">blocksMap.nodeIterator(blocks[curBlk]); </span><span class="keyword">it.hasNext();) </span>{

    DatanodeDescriptor <span class="preprocessor">dn</span> = <span class="keyword">it.next();
</span>
    <span class="keyword">boolean </span>replicaCorrupt = corruptReplicas.isReplicaCorrupt(<span class="keyword">blocks[curBlk], </span><span class="preprocessor">dn</span>)<span class="comment">;</span>

    <span class="preprocessor">if</span> (<span class="keyword">blockCorrupt </span><span class="title">||</span> (!<span class="keyword">blockCorrupt </span>&amp;&amp; !replicaCorrupt))

      machineSet[numNodes++] = <span class="preprocessor">dn</span><span class="comment">;</span>

  }

}

//使用此machineSet和当前的<span class="keyword">block构造一个LocatedBlock
</span>
<span class="label">results.add</span>(new LocatedBlock(<span class="keyword">blocks[curBlk], </span>machineSet, curPos,

            <span class="keyword">blockCorrupt));
</span>
<span class="label">curPos</span> += <span class="keyword">blocks[curBlk].getNumBytes();
</span>
<span class="label">curBlk</span>++<span class="comment">;</span>

} <span class="preprocessor">while</span> (curPos &lt; endOff

    &amp;&amp; curBlk &lt; <span class="keyword">blocks.length
</span>
    &amp;&amp; results.size() &lt; nrBlocksToReturn)<span class="comment">;</span>

  //使用此LocatedBlock链表构造一个LocatedBlocks对象返回

  return inode.createLocatedBlocks(results)<span class="comment">;</span>

}
</code></pre><p>1.3、客户端<br>通过RPC调用，在NameNode得到的LocatedBlocks对象，作为成员变量构造DFSInputStream对象，最后包装为FSDataInputStream返回给用户。</p>
<p>二、文件的读取<br>2.1、客户端<br>文件读取的时候，客户端利用文件打开的时候得到的FSDataInputStream.read(long position, byte[] buffer, int offset, int length)函数进行文件读操作。</p>
<p>FSDataInputStream会调用其封装的DFSInputStream的read(long position, byte[] buffer, int offset, int length)函数，实现如下：</p>
<pre><code><span class="keyword">public</span> <span class="function"><span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">byte</span>[] buffer, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span>

  <span class="keyword">throws</span> IOException </span>{

  <span class="keyword">long</span> filelen = getFileLength();

  <span class="keyword">int</span> realLen = length;

  <span class="keyword">if</span> ((position + length) &gt; filelen) {

    realLen = (<span class="keyword">int</span>)(filelen - position);

  }

  <span class="comment">//首先得到包含从offset到offset + length内容的block列表</span>

  <span class="comment">//比如对于64M一个block的文件系统来说，欲读取从100M开始，长度为128M的数据，则block列表包括第2，3，4块block</span>

  List&lt;LocatedBlock&gt; blockRange = getBlockRange(position, realLen);

  <span class="keyword">int</span> remaining = realLen;

  <span class="comment">//对每一个block，从中读取内容</span>

  <span class="comment">//对于上面的例子，对于第2块block，读取从36M开始，读取长度28M，对于第3块，读取整一块64M，对于第4块，读取从0开始，长度为36M，共128M数据</span>

  <span class="keyword">for</span> (LocatedBlock blk : blockRange) {

    <span class="keyword">long</span> targetStart = position - blk.getStartOffset();

    <span class="keyword">long</span> bytesToRead = Math.min(remaining, blk.getBlockSize() - targetStart);

    fetchBlockByteRange(blk, targetStart,

                        targetStart + bytesToRead - <span class="number">1</span>, buffer, offset);

    remaining -= bytesToRead;

    position += bytesToRead;

    offset += bytesToRead;

  }

  <span class="keyword">assert</span> remaining == <span class="number">0</span> : <span class="string">"Wrong number of bytes read."</span>;

  <span class="keyword">if</span> (stats != <span class="keyword">null</span>) {

    stats.incrementBytesRead(realLen);

  }

  <span class="keyword">return</span> realLen;

}
</code></pre><p>其中getBlockRange函数如下：</p>
<pre><code><span class="label">private</span> synchronized List&lt;LocatedBlock&gt; getBlockRange(long offset,

                                                      long length)

                                                    throws IOException {

  List&lt;LocatedBlock&gt; <span class="keyword">blockRange </span>= new ArrayList&lt;LocatedBlock&gt;()<span class="comment">;</span>

  //首先从缓存的locatedBlocks中查找offset所在的<span class="keyword">block在缓存链表中的位置
</span>
  int <span class="keyword">blockIdx </span>= locatedBlocks.findBlock(offset)<span class="comment">;</span>

  <span class="preprocessor">if</span> (<span class="keyword">blockIdx </span>&lt; <span class="number">0</span>) { // <span class="keyword">block </span>is not cached

    <span class="keyword">blockIdx </span>= LocatedBlocks.getInsertIndex(<span class="keyword">blockIdx);
</span>
  }

  long remaining = length<span class="comment">;</span>

  long curOff = offset<span class="comment">;</span>

  <span class="preprocessor">while</span>(remaining &gt; <span class="number">0</span>) {

    LocatedBlock <span class="keyword">blk </span>= null<span class="comment">;</span>

    //按照<span class="keyword">blockIdx的位置找到block
</span>
    <span class="preprocessor">if</span>(<span class="keyword">blockIdx </span>&lt; locatedBlocks.locatedBlockCount())

      <span class="keyword">blk </span>= locatedBlocks.get(<span class="keyword">blockIdx);
</span>
    //如果<span class="keyword">block为空，则缓存中没有此block，则直接从NameNode中查找这些block，并加入缓存
</span>
    <span class="preprocessor">if</span> (<span class="keyword">blk </span>== null <span class="title">||</span> curOff &lt; <span class="keyword">blk.getStartOffset()) </span>{

      LocatedBlocks newBlocks<span class="comment">;</span>

      newBlocks = callGetBlockLocations(namenode, src, curOff, remaining)<span class="comment">;</span>

      locatedBlocks.insertRange(<span class="keyword">blockIdx, </span>newBlocks.getLocatedBlocks())<span class="comment">;</span>

      continue<span class="comment">;</span>

    }

    //如果<span class="keyword">block找到，则放入结果集
</span>
    <span class="keyword">blockRange.add(blk);
</span>
    long <span class="keyword">bytesRead </span>= <span class="keyword">blk.getStartOffset() </span>+ <span class="keyword">blk.getBlockSize() </span>- curOff<span class="comment">;</span>

    remaining -= <span class="keyword">bytesRead;
</span>
    curOff += <span class="keyword">bytesRead;
</span>
    //取下一个<span class="keyword">block
</span>
    <span class="keyword">blockIdx++;
</span>
  }

  return <span class="keyword">blockRange;
</span>
}
</code></pre><p>其中fetchBlockByteRange实现如下：<br>    private void fetchBlockByteRange(LocatedBlock block, long start,</p>
<pre><code>                                 long <span class="preprocessor">end</span>, <span class="keyword">byte[] </span><span class="keyword">buf, </span>int offset) throws IOException {

  Socket <span class="preprocessor">dn</span> = null<span class="comment">;</span>

  int numAttempts = <span class="keyword">block.getLocations().length;
</span>
  //此<span class="preprocessor">while</span>循环为读取失败后的重试次数

  <span class="preprocessor">while</span> (<span class="preprocessor">dn</span> == null &amp;&amp; numAttempts-- &gt; <span class="number">0</span> ) {

    //选择一个DataNode来读取数据

    DNAddrPair retval = chooseDataNode(<span class="keyword">block);
</span>
    DatanodeInfo chosenNode = retval.info<span class="comment">;</span>

    InetSocketAddress targetAddr = retval.<span class="keyword">addr;
</span>
    <span class="keyword">BlockReader </span>reader = null<span class="comment">;</span>

    try {

      //创建Socket连接到DataNode

      <span class="preprocessor">dn</span> = socketFactory.createSocket()<span class="comment">;</span>

      <span class="preprocessor">dn</span>.connect(targetAddr, socketTimeout)<span class="comment">;</span>

      <span class="preprocessor">dn</span>.setSoTimeout(socketTimeout)<span class="comment">;</span>

      int len = (int) (<span class="preprocessor">end</span> - start + <span class="number">1</span>)<span class="comment">;</span>

      //利用建立的Socket链接，生成一个reader负责从DataNode读取数据

      reader = <span class="keyword">BlockReader.newBlockReader(dn, </span>src,

                                          <span class="keyword">block.getBlock().getBlockId(),
</span>
                                          <span class="keyword">block.getBlock().getGenerationStamp(),
</span>
                                          start, len, <span class="keyword">buffersize,
</span>
                                          verifyChecksum, clientName)<span class="comment">;</span>

      //读取数据

      int nread = reader.readAll(<span class="keyword">buf, </span>offset, len)<span class="comment">;</span>

      return<span class="comment">;</span>

    } finally {

      IOUtils.closeStream(reader)<span class="comment">;</span>

      IOUtils.closeSocket(<span class="preprocessor">dn</span>)<span class="comment">;</span>

      <span class="preprocessor">dn</span> = null<span class="comment">;</span>

    }

    //如果读取失败，则将此DataNode标记为失败节点

    <span class="keyword">addToDeadNodes(chosenNode);
</span>
  }

}
</code></pre><p>BlockReader.newBlockReader函数实现如下：</p>
<pre><code><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> BlockReader <span class="title">newBlockReader</span>(<span class="params"> Socket sock, String file,

                                   <span class="keyword">long</span> blockId,

                                   <span class="keyword">long</span> genStamp,

                                   <span class="keyword">long</span> startOffset, <span class="keyword">long</span> len,

                                   <span class="keyword">int</span> bufferSize, boolean verifyChecksum,

                                   String clientName</span>)

                                   throws IOException </span>{

  <span class="comment">//使用Socket建立写入流，向DataNode发送读指令</span>

  DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

    <span class="keyword">new</span> BufferedOutputStream(NetUtils.getOutputStream(sock,HdfsConstants.WRITE_TIMEOUT)));

  <span class="keyword">out</span>.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

  <span class="keyword">out</span>.write( DataTransferProtocol.OP_READ_BLOCK );

  <span class="keyword">out</span>.writeLong( blockId );

  <span class="keyword">out</span>.writeLong( genStamp );

  <span class="keyword">out</span>.writeLong( startOffset );

  <span class="keyword">out</span>.writeLong( len );

  Text.writeString(<span class="keyword">out</span>, clientName);

  <span class="keyword">out</span>.flush();

  <span class="comment">//使用Socket建立读入流，用于从DataNode读取数据</span>

  DataInputStream <span class="keyword">in</span> = <span class="keyword">new</span> DataInputStream(

      <span class="keyword">new</span> BufferedInputStream(NetUtils.getInputStream(sock),

                              bufferSize));

  DataChecksum checksum = DataChecksum.newDataChecksum( <span class="keyword">in</span> );

  <span class="keyword">long</span> firstChunkOffset = <span class="keyword">in</span>.readLong();

  <span class="comment">//生成一个reader，主要包含读入流，用于读取数据</span>

  <span class="keyword">return</span> <span class="keyword">new</span> BlockReader( file, blockId, <span class="keyword">in</span>, checksum, verifyChecksum,

                          startOffset, firstChunkOffset, sock );

}
</code></pre><p>BlockReader的readAll函数就是用上面生成的DataInputStream读取数据。</p>
<p>2.2、DataNode<br>在DataNode启动的时候，会调用函数startDataNode，其中与数据读取有关的逻辑如下：</p>
<pre><code><span class="function"><span class="keyword">void</span> <span class="title">startDataNode</span><span class="params">(Configuration conf,

                   AbstractList&lt;File&gt; dataDirs

                   )</span> <span class="keyword">throws</span> IOException </span>{

  ……

  <span class="comment">// 建立一个ServerSocket，并生成一个DataXceiverServer来监控客户端的链接</span>

  ServerSocket ss = (socketWriteTimeout &gt; <span class="number">0</span>) ?

        ServerSocketChannel.open().socket() : <span class="keyword">new</span> ServerSocket();

  Server.bind(ss, socAddr, <span class="number">0</span>);

  ss.setReceiveBufferSize(DEFAULT_DATA_SOCKET_SIZE);

  <span class="comment">// adjust machine name with the actual port</span>

  tmpPort = ss.getLocalPort();

  selfAddr = <span class="keyword">new</span> InetSocketAddress(ss.getInetAddress().getHostAddress(),

                                   tmpPort);

  <span class="keyword">this</span>.dnRegistration.setName(machineName + <span class="string">":"</span> + tmpPort);

  <span class="keyword">this</span>.threadGroup = <span class="keyword">new</span> ThreadGroup(<span class="string">"dataXceiverServer"</span>);

  <span class="keyword">this</span>.dataXceiverServer = <span class="keyword">new</span> Daemon(threadGroup,

      <span class="keyword">new</span> DataXceiverServer(ss, conf, <span class="keyword">this</span>));

  <span class="keyword">this</span>.threadGroup.setDaemon(<span class="keyword">true</span>); <span class="comment">// auto destroy when empty</span>

  ……

}
</code></pre><p>DataXceiverServer.run()函数如下：</p>
<pre><code><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>{

  <span class="keyword">while</span> (datanode.shouldRun) {

      <span class="comment">//接受客户端的链接</span>

      Socket s = ss.accept();

      s.setTcpNoDelay(<span class="keyword">true</span>);

      <span class="comment">//生成一个线程DataXceiver来对建立的链接提供服务</span>

      <span class="keyword">new</span> Daemon(datanode.threadGroup,

          <span class="keyword">new</span> DataXceiver(s, datanode, <span class="keyword">this</span>)).start();

  }

  <span class="keyword">try</span> {

    ss.close();

  } <span class="keyword">catch</span> (IOException ie) {

    LOG.warn(datanode.dnRegistration + <span class="string">":DataXceiveServer: "</span>

                            + StringUtils.stringifyException(ie));

  }

}
</code></pre><p>DataXceiver.run()函数如下：</p>
<pre><code><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span>(<span class="params"></span>) </span>{

  DataInputStream <span class="keyword">in</span>=<span class="keyword">null</span>;

  <span class="keyword">try</span> {

    <span class="comment">//建立一个输入流，读取客户端发送的指令</span>

    <span class="keyword">in</span> = <span class="keyword">new</span> DataInputStream(

        <span class="keyword">new</span> BufferedInputStream(NetUtils.getInputStream(s),

                                SMALL_BUFFER_SIZE));

    <span class="keyword">short</span> version = <span class="keyword">in</span>.readShort();

    boolean local = s.getInetAddress().equals(s.getLocalAddress());

    <span class="keyword">byte</span> op = <span class="keyword">in</span>.readByte();

    <span class="comment">// Make sure the xciver count is not exceeded</span>

    <span class="keyword">int</span> curXceiverCount = datanode.getXceiverCount();

    <span class="keyword">long</span> startTime = DataNode.now();

    <span class="keyword">switch</span> ( op ) {

    <span class="comment">//读取</span>

    <span class="keyword">case</span> DataTransferProtocol.OP_READ_BLOCK:

      <span class="comment">//真正的读取数据</span>

      readBlock( <span class="keyword">in</span> );

      datanode.myMetrics.readBlockOp.inc(DataNode.now() - startTime);

      <span class="keyword">if</span> (local)

        datanode.myMetrics.readsFromLocalClient.inc();

      <span class="keyword">else</span>

        datanode.myMetrics.readsFromRemoteClient.inc();

      <span class="keyword">break</span>;

    <span class="comment">//写入</span>

    <span class="keyword">case</span> DataTransferProtocol.OP_WRITE_BLOCK:

      <span class="comment">//真正的写入数据</span>

      writeBlock( <span class="keyword">in</span> );

      datanode.myMetrics.writeBlockOp.inc(DataNode.now() - startTime);

      <span class="keyword">if</span> (local)

        datanode.myMetrics.writesFromLocalClient.inc();

      <span class="keyword">else</span>

        datanode.myMetrics.writesFromRemoteClient.inc();

      <span class="keyword">break</span>;

    <span class="comment">//其他的指令</span>

    ……

    }

  } <span class="keyword">catch</span> (Throwable t) {

    LOG.error(datanode.dnRegistration + <span class="string">":DataXceiver"</span>,t);

  } <span class="keyword">finally</span> {

    IOUtils.closeStream(<span class="keyword">in</span>);

    IOUtils.closeSocket(s);

    dataXceiverServer.childSockets.remove(s);

  }

}



<span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readBlock</span>(<span class="params">DataInputStream <span class="keyword">in</span></span>) throws IOException </span>{

  <span class="comment">//读取指令</span>

  <span class="keyword">long</span> blockId = <span class="keyword">in</span>.readLong();         

  Block block = <span class="keyword">new</span> Block( blockId, <span class="number">0</span> , <span class="keyword">in</span>.readLong());

  <span class="keyword">long</span> startOffset = <span class="keyword">in</span>.readLong();

  <span class="keyword">long</span> length = <span class="keyword">in</span>.readLong();

  String clientName = Text.readString(<span class="keyword">in</span>);

  <span class="comment">//创建一个写入流，用于向客户端写数据</span>

  OutputStream baseStream = NetUtils.getOutputStream(s,

      datanode.socketWriteTimeout);

  DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

               <span class="keyword">new</span> BufferedOutputStream(baseStream, SMALL_BUFFER_SIZE));

  <span class="comment">//生成BlockSender用于读取本地的block的数据，并发送给客户端</span>

  <span class="comment">//BlockSender有一个成员变量InputStream blockIn用于读取本地block的数据</span>

  BlockSender blockSender = <span class="keyword">new</span> BlockSender(block, startOffset, length,

          <span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, datanode, clientTraceFmt);

   <span class="keyword">out</span>.writeShort(DataTransferProtocol.OP_STATUS_SUCCESS); <span class="comment">// send op status</span>

   <span class="comment">//向客户端写入数据</span>

   <span class="keyword">long</span> read = blockSender.sendBlock(<span class="keyword">out</span>, baseStream, <span class="keyword">null</span>);

   ……

  } <span class="keyword">finally</span> {

    IOUtils.closeStream(<span class="keyword">out</span>);

    IOUtils.closeStream(blockSender);

  }

}
</code></pre><p>三、文件的写入<br>下面解析向hdfs上传一个文件的过程。</p>
<p>3.1、客户端<br>上传一个文件到hdfs，一般会调用DistributedFileSystem.create，其实现如下：</p>
<pre><code><span class="keyword">public</span> <span class="function">FSDataOutputStream <span class="title">create</span><span class="params">(Path f, FsPermission permission,

  <span class="keyword">boolean</span> overwrite,

  <span class="keyword">int</span> bufferSize, <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize,

  Progressable progress)</span> <span class="keyword">throws</span> IOException </span>{

  <span class="keyword">return</span> <span class="keyword">new</span> FSDataOutputStream

     (dfs.create(getPathName(f), permission,

                 overwrite, replication, blockSize, progress, bufferSize),

      statistics);

}
</code></pre><p>其最终生成一个FSDataOutputStream用于向新生成的文件中写入数据。其成员变量dfs的类型为DFSClient，DFSClient的create函数如下：</p>
<pre><code>public <span class="type">OutputStream</span> create(<span class="type">String</span> src,

                         <span class="type">FsPermission</span> permission,

                         boolean overwrite,

                         short replication,

                         long blockSize,

                         <span class="type">Progressable</span> progress,

                         <span class="type">int</span> buffersize

                         ) throws <span class="type">IOException</span> {

checkOpen();

<span class="keyword">if</span> (permission == null) {

  permission = <span class="type">FsPermission</span>.getDefault();

}

<span class="type">FsPermission</span> masked = permission.applyUMask(<span class="type">FsPermission</span>.getUMask(conf));

<span class="type">OutputStream</span> <span class="literal">result</span> = new <span class="type">DFSOutputStream</span>(src, masked,

    overwrite, replication, blockSize, progress, buffersize,

    conf.getInt(<span class="string">"io.bytes.per.checksum"</span>, <span class="number">512</span>));

leasechecker.put(src, <span class="literal">result</span>);

<span class="keyword">return</span> <span class="literal">result</span>;
</code></pre><p>  }</p>
<p>其中构造了一个DFSOutputStream，在其构造函数中，同过RPC调用NameNode的create来创建一个文件。<br>当然，构造函数中还做了一件重要的事情，就是streamer.start()，也即启动了一个pipeline，用于写数据，在写入数据的过程中，我们会仔细分析。</p>
<pre><code>DFSOutputStream(String src, FsPermission masked, <span class="keyword">boolean</span> overwrite,

  <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, Progressable progress,

  <span class="keyword">int</span> buffersize, <span class="keyword">int</span> bytesPerChecksum) <span class="keyword">throws</span> IOException {

<span class="keyword">this</span>(src, blockSize, progress, bytesPerChecksum);

computePacketChunkSize(writePacketSize, bytesPerChecksum);

<span class="keyword">try</span> {

  namenode.create(

      src, masked, clientName, overwrite, replication, blockSize);

} <span class="keyword">catch</span>(RemoteException re) {

  <span class="keyword">throw</span> re.unwrapRemoteException(AccessControlException.<span class="keyword">class</span>,

                                 QuotaExceededException.<span class="keyword">class</span>);

}

streamer.start();

  }
</code></pre><p>3.2、NameNode<br>NameNode的create函数调用namesystem.startFile函数，其又调用startFileInternal函数，实现如下：</p>
<pre><code><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> startFileInternal(<span class="keyword">String</span> src,

                                         PermissionStatus permissions,

                                         <span class="keyword">String</span> holder,

                                         <span class="keyword">String</span> clientMachine,

                                         <span class="built_in">boolean</span> overwrite,

                                         <span class="built_in">boolean</span> <span class="built_in">append</span>,

                                         <span class="keyword">short</span> replication,

                                         <span class="keyword">long</span> blockSize

                                         ) <span class="keyword">throws</span> IOException {

   ......

  <span class="comment">//创建一个新的文件，状态为under construction，没有任何data block与之对应</span>

  <span class="keyword">long</span> genstamp = nextGenerationStamp();

  INodeFileUnderConstruction newNode = dir.addFile(src, permissions,

     replication, blockSize, holder, clientMachine, clientNode, genstamp);

  ......

 }
</code></pre><p>3.3、客户端<br>下面轮到客户端向新创建的文件中写入数据了，一般会使用FSDataOutputStream的write函数，最终会调用DFSOutputStream的writeChunk函数：</p>
<p>按照hdfs的设计，对block的数据写入使用的是pipeline的方式，也即将数据分成一个个的package，如果需要复制三分，分别写入DataNode 1, 2, 3，则会进行如下的过程：</p>
<p>首先将package 1写入DataNode 1<br>然后由DataNode 1负责将package 1写入DataNode 2，同时客户端可以将pacage 2写入DataNode 1<br>然后DataNode 2负责将package 1写入DataNode 3, 同时客户端可以讲package 3写入DataNode 1，DataNode 1将package 2写入DataNode 2<br>就这样将一个个package排着队的传递下去，直到所有的数据全部写入并复制完毕<br>  protected synchronized void writeChunk(byte[] b, int offset, int len, byte[] checksum)</p>
<pre><code>                                                    <span class="keyword">throws</span> IOException {

  <span class="comment">//创建一个package，并写入数据</span>

  currentPacket = <span class="keyword">new</span> Packet(packetSize, chunksPerPacket,

                               bytesCurBlock);

  currentPacket.writeChecksum(checksum, <span class="number">0</span>, cklen);

  currentPacket.writeData(b, offset, len);

  currentPacket.numChunks++;

  bytesCurBlock += len;

  <span class="comment">//如果此package已满，则放入队列中准备发送</span>

  <span class="keyword">if</span> (currentPacket.numChunks == currentPacket.maxChunks ||

      bytesCurBlock == blockSize) {

      ......

      dataQueue.addLast(currentPacket);

      <span class="comment">//唤醒等待dataqueue的传输线程，也即DataStreamer</span>

      dataQueue.notifyAll();

      currentPacket = <span class="keyword">null</span>;

      ......

  }

  }


DataStreamer的run函数如下：

  <span class="keyword">public</span> <span class="keyword">void</span> run() {

    <span class="keyword">while</span> (!closed &amp;&amp; clientRunning) {

      Packet one = <span class="keyword">null</span>;

      <span class="keyword">synchronized</span> (dataQueue) {

        <span class="comment">//如果队列中没有package，则等待</span>

        <span class="keyword">while</span> ((!closed &amp;&amp; !hasError &amp;&amp; clientRunning

               &amp;&amp; dataQueue.<span class="keyword">size</span>() == <span class="number">0</span>) || doSleep) {

          <span class="keyword">try</span> {

            dataQueue.wait(<span class="number">1000</span>);

          } <span class="keyword">catch</span> (InterruptedException  e) {

          }

          doSleep = <span class="keyword">false</span>;

        }

        <span class="keyword">try</span> {

          <span class="comment">//得到队列中的第一个package</span>

          one = dataQueue.getFirst();

          <span class="keyword">long</span> offsetInBlock = one.offsetInBlock;

          <span class="comment">//由NameNode分配block，并生成一个写入流指向此block</span>

          <span class="keyword">if</span> (blockStream == <span class="keyword">null</span>) {

            nodes = nextBlockOutputStream(src);

            response = <span class="keyword">new</span> ResponseProcessor(nodes);

            response.start();

          }

          ByteBuffer buf = one.getBuffer();

          <span class="comment">//将package从dataQueue移至ackQueue,等待确认</span>

          dataQueue.removeFirst();

          dataQueue.notifyAll();

          <span class="keyword">synchronized</span> (ackQueue) {

            ackQueue.addLast(one);

            ackQueue.notifyAll();

          }

      <span class="comment">//利用生成的写入流将数据写入DataNode中的block</span>

      blockStream.<span class="keyword">write</span>(buf.array(), buf.position(), buf.remaining());

      <span class="keyword">if</span> (one.lastPacketInBlock) {

        blockStream.writeInt(<span class="number">0</span>); <span class="comment">//表示此block写入完毕</span>

      }

      blockStream.flush();

    } <span class="keyword">catch</span> (Throwable e) {

    }

  }

  ......

 }
</code></pre><p>其中重要的一个函数是nextBlockOutputStream，实现如下：</p>
<pre><code> <span class="keyword">private</span> DatanodeInfo[] nextBlockOutputStream(String client) <span class="keyword">throws</span> IOException {

LocatedBlock lb = <span class="keyword">null</span>;

<span class="keyword">boolean</span> retry = <span class="keyword">false</span>;

DatanodeInfo[] nodes;

<span class="keyword">int</span> <span class="keyword">count</span> = conf.getInt(<span class="string">"dfs.client.block.write.retries"</span>, <span class="number">3</span>);

<span class="keyword">boolean</span> success;

<span class="keyword">do</span> {

  ......

  <span class="comment">//由NameNode为文件分配DataNode和block</span>

  lb = locateFollowingBlock(startTime);

  block = lb.getBlock();

  nodes = lb.getLocations();

  <span class="comment">//创建向DataNode的写入流</span>

  success = createBlockOutputStream(nodes, clientName, <span class="keyword">false</span>);

  ......

} <span class="keyword">while</span> (retry &amp;&amp; --<span class="keyword">count</span> &gt;= <span class="number">0</span>);

<span class="keyword">return</span> nodes;

}
</code></pre><p>locateFollowingBlock中通过RPC调用namenode.addBlock(src, clientName)函数</p>
<p>3.4、NameNode<br>NameNode的addBlock函数实现如下：</p>
<pre><code> <span class="keyword">public</span> LocatedBlock addBlock(<span class="keyword">String</span> src,

                           <span class="keyword">String</span> clientName) <span class="keyword">throws</span> IOException {

    LocatedBlock locatedBlock = namesystem.getAdditionalBlock(src, clientName);

    <span class="keyword">return</span> locatedBlock;

  }

FSNamesystem的getAdditionalBlock实现如下：

  <span class="keyword">public</span> LocatedBlock getAdditionalBlock(<span class="keyword">String</span> src,

                                     <span class="keyword">String</span> clientName

                                     ) <span class="keyword">throws</span> IOException {

<span class="keyword">long</span> fileLength, blockSize;

<span class="built_in">int</span> replication;

DatanodeDescriptor clientNode = <span class="keyword">null</span>;

Block newBlock = <span class="keyword">null</span>;

......

<span class="comment">//为新的block选择DataNode</span>

DatanodeDescriptor targets[] = replicator.chooseTarget(replication,

                                                       clientNode,

                                                       <span class="keyword">null</span>,

                                                       blockSize);

......

<span class="comment">//得到文件路径中所有path的INode，其中最后一个是新添加的文件对的INode，状态为under construction</span>

INode[] pathINodes = dir.getExistingPathINodes(src);

<span class="built_in">int</span> inodesLen = pathINodes.length;

INodeFileUnderConstruction pendingFile  = (INodeFileUnderConstruction)

                                            pathINodes[inodesLen - <span class="number">1</span>];

<span class="comment">//为文件分配block, 并设置在那写DataNode上</span>

newBlock = allocateBlock(src, pathINodes);

pendingFile.setTargets(targets);

......

<span class="keyword">return</span> <span class="keyword">new</span> LocatedBlock(newBlock, targets, fileLength);

}
</code></pre><p>3.5、客户端<br>在分配了DataNode和block以后，createBlockOutputStream开始写入数据。</p>
<pre><code><span class="function"><span class="keyword">private</span> boolean <span class="title">createBlockOutputStream</span>(<span class="params">DatanodeInfo[] nodes, String client,

              boolean recoveryFlag</span>) </span>{

  <span class="comment">//创建一个socket，链接DataNode</span>

  InetSocketAddress target = NetUtils.createSocketAddr(nodes[<span class="number">0</span>].getName());

  s = socketFactory.createSocket();

  <span class="keyword">int</span> timeoutValue = <span class="number">3000</span> * nodes.length + socketTimeout;

  s.connect(target, timeoutValue);

  s.setSoTimeout(timeoutValue);

  s.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);

  <span class="keyword">long</span> writeTimeout = HdfsConstants.WRITE_TIMEOUT_EXTENSION * nodes.length +

                      datanodeWriteTimeout;

  DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

      <span class="keyword">new</span> BufferedOutputStream(NetUtils.getOutputStream(s, writeTimeout),

                               DataNode.SMALL_BUFFER_SIZE));

  blockReplyStream = <span class="keyword">new</span> DataInputStream(NetUtils.getInputStream(s));

  <span class="comment">//写入指令</span>

  <span class="keyword">out</span>.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

  <span class="keyword">out</span>.write( DataTransferProtocol.OP_WRITE_BLOCK );

  <span class="keyword">out</span>.writeLong( block.getBlockId() );

  <span class="keyword">out</span>.writeLong( block.getGenerationStamp() );

  <span class="keyword">out</span>.writeInt( nodes.length );

  <span class="keyword">out</span>.writeBoolean( recoveryFlag );

  Text.writeString( <span class="keyword">out</span>, client );

  <span class="keyword">out</span>.writeBoolean(<span class="keyword">false</span>);

  <span class="keyword">out</span>.writeInt( nodes.length - <span class="number">1</span> );

  <span class="comment">//注意，次循环从1开始，而非从0开始。将除了第一个DataNode以外的另外两个DataNode的信息发送给第一个DataNode, 第一个DataNode可以根据此信息将数据写给另两个DataNode</span>

  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nodes.length; i++) {

    nodes[i].write(<span class="keyword">out</span>);

  }

  checksum.writeHeader( <span class="keyword">out</span> );

  <span class="keyword">out</span>.flush();

  firstBadLink = Text.readString(blockReplyStream);

  <span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) {

    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink "</span> + firstBadLink);

  }

  blockStream = <span class="keyword">out</span>;
</code></pre><p>  }</p>
<p>客户端在DataStreamer的run函数中创建了写入流后，调用blockStream.write将数据写入DataNode</p>
<p>3.6、DataNode<br>    DataNode的DataXceiver中，收到指令DataTransferProtocol.OP_WRITE_BLOCK则调用writeBlock函数：</p>
<pre><code>private <span class="keyword">void</span> writeBlock(DataInputStream <span class="keyword">in</span>) throws IOException {

DatanodeInfo srcDataNode = <span class="keyword">null</span>;

<span class="comment">//读入头信息</span>

Block block = <span class="keyword">new</span> Block(<span class="keyword">in</span>.readLong(),

    dataXceiverServer.estimateBlockSize, <span class="keyword">in</span>.readLong());

<span class="built_in">int</span> pipelineSize = <span class="keyword">in</span>.readInt(); <span class="comment">// num of datanodes in entire pipeline</span>

boolean isRecovery = <span class="keyword">in</span>.readBoolean(); <span class="comment">// is this part of recovery?</span>

<span class="built_in">String</span> client = Text.readString(<span class="keyword">in</span>); <span class="comment">// working on behalf of this client</span>

boolean hasSrcDataNode = <span class="keyword">in</span>.readBoolean(); <span class="comment">// is src node info present</span>

<span class="keyword">if</span> (hasSrcDataNode) {

  srcDataNode = <span class="keyword">new</span> DatanodeInfo();

  srcDataNode.readFields(<span class="keyword">in</span>);

}

<span class="built_in">int</span> numTargets = <span class="keyword">in</span>.readInt();

<span class="keyword">if</span> (numTargets &lt; <span class="number">0</span>) {

  <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Mislabelled incoming datastream."</span>);

}

<span class="comment">//读入剩下的DataNode列表，如果当前是第一个DataNode，则此列表中收到的是第二个，第三个DataNode的信息，如果当前是第二个DataNode，则受到的是第三个DataNode的信息</span>

DatanodeInfo targets[] = <span class="keyword">new</span> DatanodeInfo[numTargets];

<span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; targets.length; i++) {

  DatanodeInfo tmp = <span class="keyword">new</span> DatanodeInfo();

  tmp.readFields(<span class="keyword">in</span>);

  targets[i] = tmp;

}

DataOutputStream mirrorOut = <span class="keyword">null</span>;  <span class="comment">// stream to next target</span>

DataInputStream mirrorIn = <span class="keyword">null</span>;    <span class="comment">// reply from next target</span>

DataOutputStream replyOut = <span class="keyword">null</span>;   <span class="comment">// stream to prev target</span>

Socket mirrorSock = <span class="keyword">null</span>;           <span class="comment">// socket to next target</span>

BlockReceiver blockReceiver = <span class="keyword">null</span>; <span class="comment">// responsible for data handling</span>

<span class="built_in">String</span> mirrorNode = <span class="keyword">null</span>;           <span class="comment">// the name:port of next target</span>

<span class="built_in">String</span> firstBadLink = <span class="string">""</span>;           <span class="comment">// first datanode that failed in connection setup</span>

<span class="keyword">try</span> {

  <span class="comment">//生成一个BlockReceiver, 其有成员变量DataInputStream in为从客户端或者上一个DataNode读取数据，还有成员变量DataOutputStream mirrorOut，用于向下一个DataNode写入数据，还有成员变量OutputStream out用于将数据写入本地。</span>

  blockReceiver = <span class="keyword">new</span> BlockReceiver(block, <span class="keyword">in</span>,

      s.getRemoteSocketAddress().toString(),

      s.getLocalSocketAddress().toString(),

      isRecovery, client, srcDataNode, datanode);

  <span class="comment">// get a connection back to the previous target</span>

  replyOut = <span class="keyword">new</span> DataOutputStream(

                 NetUtils.getOutputStream(s, datanode.socketWriteTimeout));

  <span class="comment">//如果当前不是最后一个DataNode，则同下一个DataNode建立socket连接</span>

  <span class="keyword">if</span> (targets.length &gt; <span class="number">0</span>) {

    InetSocketAddress mirrorTarget = <span class="keyword">null</span>;

    <span class="comment">// Connect to backup machine</span>

    mirrorNode = targets[<span class="number">0</span>].getName();

    mirrorTarget = NetUtils.createSocketAddr(mirrorNode);

    mirrorSock = datanode.newSocket();

    <span class="built_in">int</span> timeoutValue = numTargets * datanode.socketTimeout;

    <span class="built_in">int</span> writeTimeout = datanode.socketWriteTimeout +

                         (HdfsConstants.WRITE_TIMEOUT_EXTENSION * numTargets);

    mirrorSock.connect(mirrorTarget, timeoutValue);

    mirrorSock.setSoTimeout(timeoutValue);

    mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);

    <span class="comment">//创建向下一个DataNode写入数据的流</span>

    mirrorOut = <span class="keyword">new</span> DataOutputStream(

         <span class="keyword">new</span> BufferedOutputStream(

                     NetUtils.getOutputStream(mirrorSock, writeTimeout),

                     SMALL_BUFFER_SIZE));

    mirrorIn = <span class="keyword">new</span> DataInputStream(NetUtils.getInputStream(mirrorSock));

    mirrorOut.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

    mirrorOut.write( DataTransferProtocol.OP_WRITE_BLOCK );

    mirrorOut.writeLong( block.getBlockId() );

    mirrorOut.writeLong( block.getGenerationStamp() );

    mirrorOut.writeInt( pipelineSize );

    mirrorOut.writeBoolean( isRecovery );

    Text.writeString( mirrorOut, client );

    mirrorOut.writeBoolean(hasSrcDataNode);

    <span class="keyword">if</span> (hasSrcDataNode) { <span class="comment">// pass src node information</span>

      srcDataNode.write(mirrorOut);

    }

    mirrorOut.writeInt( targets.length - <span class="number">1</span> );

    <span class="comment">//此出也是从1开始，将除了下一个DataNode的其他DataNode信息发送给下一个DataNode</span>

    <span class="keyword">for</span> ( <span class="built_in">int</span> i = <span class="number">1</span>; i &lt; targets.length; i++ ) {

      targets[i].write( mirrorOut );

    }

    blockReceiver.writeChecksumHeader(mirrorOut);

    mirrorOut.flush();

  }

  <span class="comment">//使用BlockReceiver接受block</span>

  <span class="built_in">String</span> mirrorAddr = (mirrorSock == <span class="keyword">null</span>) ? <span class="keyword">null</span> : mirrorNode;

  blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,

                             mirrorAddr, <span class="keyword">null</span>, targets.length);

  ......

} <span class="keyword">finally</span> {

  <span class="comment">// close all opened streams</span>

  IOUtils.closeStream(mirrorOut);

  IOUtils.closeStream(mirrorIn);

  IOUtils.closeStream(replyOut);

  IOUtils.closeSocket(mirrorSock);

  IOUtils.closeStream(blockReceiver);

}

}
</code></pre><p>BlockReceiver的receiveBlock函数中，一段重要的逻辑如下：</p>
<pre><code><span class="function"><span class="keyword">void</span> <span class="title">receiveBlock</span><span class="params">(

  DataOutputStream mirrOut, <span class="comment">// output to next datanode</span>

  DataInputStream mirrIn,   <span class="comment">// input from next datanode</span>

  DataOutputStream replyOut,  <span class="comment">// output to previous datanode</span>

  String mirrAddr, BlockTransferThrottler throttlerArg,

  <span class="keyword">int</span> numTargets)</span> throws IOException </span>{

  ......

  <span class="comment">//不断的接受package，直到结束</span>

  <span class="keyword">while</span> (receivePacket() &gt; <span class="number">0</span>) {}

  <span class="keyword">if</span> (mirrorOut != null) {

    <span class="keyword">try</span> {

      mirrorOut.writeInt(<span class="number">0</span>); <span class="comment">// mark the end of the block</span>

      mirrorOut.flush();

    } <span class="keyword">catch</span> (IOException e) {

      handleMirrorOutError(e);

    }

  }

  ......
</code></pre><p>  }</p>
<p>BlockReceiver的receivePacket函数如下：</p>
<pre><code> <span class="keyword">private</span> <span class="function"><span class="keyword">int</span> <span class="title">receivePacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>{

<span class="comment">//从客户端或者上一个节点接收一个package</span>

<span class="keyword">int</span> payloadLen = readNextPacket();

buf.mark();

<span class="comment">//read the header</span>

buf.getInt(); <span class="comment">// packet length</span>

offsetInBlock = buf.getLong(); <span class="comment">// get offset of packet in block</span>

<span class="keyword">long</span> seqno = buf.getLong();    <span class="comment">// get seqno</span>

<span class="keyword">boolean</span> lastPacketInBlock = (buf.get() != <span class="number">0</span>);

<span class="keyword">int</span> endOfHeader = buf.position();

buf.reset();

setBlockPosition(offsetInBlock);

<span class="comment">//将package写入下一个DataNode</span>

<span class="keyword">if</span> (mirrorOut != <span class="keyword">null</span>) {

  <span class="keyword">try</span> {

    mirrorOut.write(buf.array(), buf.position(), buf.remaining());

    mirrorOut.flush();

  } <span class="keyword">catch</span> (IOException e) {

    handleMirrorOutError(e);

  }

}

buf.position(endOfHeader);       

<span class="keyword">int</span> len = buf.getInt();

offsetInBlock += len;

<span class="keyword">int</span> checksumLen = ((len + bytesPerChecksum - <span class="number">1</span>)/bytesPerChecksum)*

                                                        checksumSize;

<span class="keyword">int</span> checksumOff = buf.position();

<span class="keyword">int</span> dataOff = checksumOff + checksumLen;

<span class="keyword">byte</span> pktBuf[] = buf.array();

buf.position(buf.limit()); <span class="comment">// move to the end of the data.</span>

......

<span class="comment">//将数据写入本地的block</span>

out.write(pktBuf, dataOff, len);

<span class="comment">/// flush entire packet before sending ack</span>

flush();

<span class="comment">// put in queue for pending acks</span>

<span class="keyword">if</span> (responder != <span class="keyword">null</span>) {

  ((PacketResponder)responder.getRunnable()).enqueue(seqno,

                                  lastPacketInBlock);

}

<span class="keyword">return</span> payloadLen;

}
</code></pre>
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://linrunzhang.github.io/2015/11/26/hadoop-读写分析/" data-id="cihfto8oa0004h6yn6olf3gcv" class="article-share-link" data-share="baidu" data-title="hadoop 读写分析">分享到</a>
      

      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hadoop-heatbeats" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/26/hadoop-heatbeats/" class="article-date">
  <time datetime="2015-11-26T02:52:36.000Z" itemprop="datePublished">2015-11-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/26/hadoop-heatbeats/">hadoop heatbeats</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>hadoop的心跳过程：</p>
<p> 1) master启动的时候，会开一个ipc server在那里。<br> 2) slave启动时，会连接master，并每隔3秒钟主动向master发送一个“心跳”，将自己的状态信息告诉master，然后master也是通过这个心跳的返回值，向slave节点传达指令。</p>
<p>2、找到心跳的代码</p>
<p> 拿namenode和datanode来说，在datanode的offerService方法中，每隔3秒向namenode发送心跳的代码：</p>
<pre><code><span class="comment">/** 
* Main loop for the DataNode.  Runs until shutdown, 
* forever calling remote NameNode functions. 
*/</span>  
<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">offerService</span>(<span class="params"></span>) throws Exception </span>{  
...  
<span class="comment">//  </span>
<span class="comment">// Now loop for a long time....  </span>
<span class="comment">//  </span>
<span class="keyword">while</span> (shouldRun) {  
 <span class="keyword">try</span> {  
   <span class="keyword">long</span> startTime = now();  

   <span class="comment">//  </span>
   <span class="comment">// Every so often, send heartbeat or block-report  </span>
   <span class="comment">//  </span>

<span class="comment">// 如果到了3秒钟，就向namenode发心跳  </span>
<span class="keyword">if</span> (startTime - lastHeartbeat &gt; heartBeatInterval) {  
   <span class="comment">//  </span>
   <span class="comment">// All heartbeat messages include following info:  </span>
   <span class="comment">// -- Datanode name  </span>
   <span class="comment">// -- data transfer port  </span>
   <span class="comment">// -- Total capacity  </span>
   <span class="comment">// -- Bytes remaining  </span>
   <span class="comment">//  </span>
   lastHeartbeat = startTime;  
   DatanodeCommand[] cmds = namenode.sendHeartbeat(dnRegistration,  
                                                data.getCapacity(),  
                                                data.getDfsUsed(),  
                                                data.getRemaining(),  
                                                xmitsInProgress.<span class="keyword">get</span>(),  
                                                getXceiverCount());  

<span class="comment">// 注意上面这行代码，“发送心跳”竟然就是调用namenode的一个方法？？  </span>

myMetrics.heartbeats.inc(now() - startTime);  
<span class="comment">//LOG.info("Just sent heartbeat, with name " + localName);  </span>

<span class="comment">// 处理对心跳的返回值（namenode传给datanode的指令）  </span>
<span class="keyword">if</span> (!processCommand(cmds))  
       <span class="keyword">continue</span>;  
}  

<span class="comment">// 这里省略很多代码  </span>
...  
} <span class="comment">// while (shouldRun)  </span>
} <span class="comment">// offerService  </span>
</code></pre><p>上面这段代码，如果是单机的程序，没什么值得奇怪的。但是，这是hadoop集群！datanode和namenode在2台不同的机器（或2个JVM）上运行！datanode机器竟然直接调用namenode的方法！这是怎么实现的？难道是传说中的RMI吗？？</p>
<p>下面我们主要就来分析这个方法调用的细节。</p>
<p>3、心跳的底层细节一：datanode怎么获得namenode对象的？</p>
<p>首先，DataNode类中，有一个namenode的成员变量：</p>
<pre><code>public <span class="class"><span class="keyword">class</span> <span class="title">DataNode</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">Configured</span>   
</span>implements <span class="type">InterDatanodeProtocol</span>, <span class="type">ClientDatanodeProtocol</span>, <span class="type">FSConstants</span>, <span class="type">Runnable</span> {  
...  
public <span class="type">DatanodeProtocol</span> namenode = <span class="literal">null</span>;  
...   
}  
</code></pre><p>下面是NameNode类的定义：</p>
<pre><code><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NameNode</span> <span class="title">implements</span> <span class="title">ClientProtocol</span>, <span class="typename">DatanodeProtocol</span>,  
                             <span class="typename">NamenodeProtocol</span>, <span class="typename">FSConstants</span>,  
                             <span class="typename">RefreshAuthorizationPolicyProtocol {  </span></span>
...   
}  
</code></pre><p>注意：NameNode实现了DatanodeProtocol接口，DatanodeProtocol接口定义了namenode和datanode之间通信的方法。</p>
<p>那么，DataNode类是怎么获取到NameNode类的引用呢？</p>
<p>在Datanode端，为namenode变量赋值的代码：</p>
<pre><code>// connect to name <span class="keyword">node</span><span class="identifier">  
</span><span class="title">this</span>.namenode = (DatanodeProtocol)   
RPC.waitForProxy(DatanodeProtocol.class,  
               DatanodeProtocol.versionID,  
               nameNodeAddr,   
               conf);  
</code></pre><p>在继续去RPC类中追踪：在继续去RPC类中追踪：</p>
<pre><code>VersionedProtocol proxy =  
    (VersionedProtocol) Proxy.newProxyInstance(  
        protocol.getClassLoader(), <span class="keyword">new</span> <span class="class"><span class="keyword">Class</span>[] { <span class="title">protocol</span> },  </span>
        <span class="keyword">new</span> Invoker(addr, ticket, conf, factory));  
</code></pre><p>现在，明白了！<br>1) 对namenode的赋值，并不是真正的new了一个实现了DatanodeProtocol接口的对象，而是获得了一个动态代理！！<br>2) 上面这段代码中，protocol的类型是DatanodeProtocol.class<br>3) 对namenode的所有调用，都被委托(delegate)给了Invoker<br>现在，明白了！<br>1) 对namenode的赋值，并不是真正的new了一个实现了DatanodeProtocol接口的对象，而是获得了一个动态代理！！<br>2) 上面这段代码中，protocol的类型是DatanodeProtocol.class<br>3) 对namenode的所有调用，都被委托(delegate)给了Invoker<br>4、心跳的底层细节二：看看Invoker类<br>Invoker类是org.apache.hadoop.ipc.RPC类的一个静态内部类： </p>
<pre><code>private <span class="keyword">static</span> class <span class="type">Invoker</span> implements <span class="type">InvocationHandler</span> {  


//所有的方法调用又被delegate给client的call方法了！

public <span class="type">Object</span> invoke(<span class="type">Object</span> proxy, <span class="type">Method</span> <span class="keyword">method</span>, <span class="type">Object</span>[] args) throws <span class="type">Throwable</span> {  
        ...  

          <span class="type">ObjectWritable</span> value = (<span class="type">ObjectWritable</span>)  
            client.call(new <span class="type">Invocation</span>(<span class="keyword">method</span>, args), address,   
                        <span class="keyword">method</span>.getDeclaringClass(), ticket);  
            ...  
          <span class="keyword">return</span> value.get();  
       }  

//client是<span class="type">Invoker</span>中的成员变量：
private <span class="type">Client</span> client;  
</code></pre><p>所以可以看出：DatanodeProtocol中的每个方法调用，都被包装成一个Invocation对象，再由client.call()调用</p>
<p>5、心跳的底层细节三：Invocation类</p>
<p>Invocation类是org.apache.hadoop.ipc.RPC类的一个静态内部类</p>
<p>没有什么业务逻辑方法，主要作用就是一个VO</p>
<p>6、心跳的底层细节四：client类的call方法</p>
<p>接下来重点看client类的call方法：</p>
<pre><code><span class="keyword">public</span> Writable <span class="keyword">call</span>(Writable param, InetSocketAddress addr,<span class="keyword">Class</span>&lt;?&gt; protocol, UserGroupInformation ticket)    
                 <span class="keyword">throws</span> InterruptedException, IOException {  
<span class="keyword">Call</span> <span class="keyword">call</span> = <span class="keyword">new</span> <span class="keyword">Call</span>(param);     
<span class="comment">// 将Invocation转化为Call  </span>
Connection connection = getConnection(addr, protocol, ticket, <span class="keyword">call</span>);  
<span class="comment">// 连接远程服务器  </span>
connection.sendParam(<span class="keyword">call</span>);                 <span class="comment">// send the parameter  </span>
<span class="comment">// 将“序列化”后的call发给过去  </span>
<span class="keyword">boolean</span> interrupted = <span class="keyword">false</span>;  
<span class="keyword">synchronized</span> (<span class="keyword">call</span>) {  
<span class="keyword">while</span> (!<span class="keyword">call</span>.done) {  
  <span class="keyword">try</span> {  
    <span class="keyword">call</span>.wait();                           <span class="comment">// wait for the result  </span>
<span class="comment">// 等待调用结果  </span>
  } <span class="keyword">catch</span> (InterruptedException ie) {  
    <span class="comment">// save the fact that we were interrupted  </span>
    interrupted = <span class="keyword">true</span>;  
  }  
}  

<span class="keyword">if</span> (interrupted) {  
  <span class="comment">// set the interrupt flag now that we are done waiting  </span>
  Thread.currentThread().interrupt();  
}  

<span class="keyword">if</span> (<span class="keyword">call</span>.error != <span class="keyword">null</span>) {  
  <span class="keyword">if</span> (<span class="keyword">call</span>.error <span class="keyword">instanceof</span> RemoteException) {  
    <span class="keyword">call</span>.error.fillInStackTrace();  
    <span class="keyword">throw</span> <span class="keyword">call</span>.error;  
  } <span class="keyword">else</span> { <span class="comment">// local exception  </span>
    <span class="keyword">throw</span> wrapException(addr, <span class="keyword">call</span>.error);  
  }  
} <span class="keyword">else</span> {  
  <span class="keyword">return</span> <span class="keyword">call</span>.value;  
<span class="comment">// 返回  </span>
}  
} 
}  
</code></pre><p>7、现在，一目了然了</p>
<p>datanode向namenode发送heartbeat过程是这样的：  </p>
<pre><code><span class="title">a</span>) 在datanode初始化获得namenode的proxy  
<span class="title">b</span>) 在datanode上，调用namenode proxy的heartbeat方法：  
    namenode.sendHeartbeat(dnRegistration,  
                           <span class="typedef"><span class="keyword">data</span>.getCapacity<span class="container">()</span>,  </span>
                           <span class="typedef"><span class="keyword">data</span>.getDfsUsed<span class="container">()</span>,  </span>
                           <span class="typedef"><span class="keyword">data</span>.getRemaining<span class="container">()</span>,  </span>
                           xmitsInProgress.get(),  
                           getXceiverCount());  
<span class="title">c</span>) 在datanode上的namenode动态代理类将这个调用包装成(或者叫“序列化成”)一个<span class="type">Invocation</span>对象，并调用client.call方法  
<span class="title">d</span>) client call方法将<span class="type">Invocation</span>转化为<span class="type">Call</span>对象  
<span class="title">e</span>) client 将call发送到真正的namenode服务器  
<span class="title">f</span>) namenode接收后，转化成namenode端的<span class="type">Call</span>，并process后，通过<span class="type">Responder</span>发回来！  
<span class="title">g</span>) datanode接收结果，并将结果转化为<span class="type">DatanodeCommand</span>[]  
</code></pre><p>8、再看动态代理</p>
<p>动态代理：让“只有接口，没事对应的实现类”成为可能，因为具体方法的实现可以委托给另一个类！！</p>
<p>在这个例子中，就datanode而言，DatanodeProtocol接口是没有实现类的！</p>
<p>9、观Hadoop HDFS 心跳时间</p>
<p>datenode以固定周期向namenode发送心跳，namenode如果在一段时间内没有收到心跳，就会标记datenode为宕机。 此段时间的计算公式是：</p>
<pre><code>timeout  = <span class="number">2</span> * heartbeat.recheck.interval + <span class="number">10</span> * dfs.heartbeat.interval
</code></pre><p>默认 heartbeat.recheck.interval 是5分钟，dfs.heartbeat.interval是3秒，所以DN挂了后，NN要确定DN为DEAR需要10min30s，也就是630S自动标识为dead。</p>
<pre><code><span class="variable">&lt;property&gt;</span>
<span class="variable">&lt;name&gt;</span>dfs.heartbeat.interval<span class="variable">&lt;/name&gt;</span>
<span class="variable">&lt;value&gt;</span><span class="number">3</span><span class="variable">&lt;/value&gt;</span> 
<span class="variable">&lt;description&gt;</span>Determines datanode heartbeat interval <span class="keyword">in</span> seconds.<span class="variable">&lt;/description&gt;</span> 
<span class="variable">&lt;/property&gt;</span>

<span class="variable">&lt;property&gt;</span>
<span class="variable">&lt;name&gt;</span>dfs.heartbeat.recheck.interval<span class="variable">&lt;/name&gt;</span>
<span class="variable">&lt;value&gt;</span><span class="number">20000</span><span class="variable">&lt;/value&gt;</span>
<span class="variable">&lt;description&gt;</span>Determines when machines are marked dead 单位：毫秒！！！<span class="variable">&lt;/description&gt;</span> 
<span class="variable">&lt;/property&gt;</span>
</code></pre><p>查看NN的日志</p>
<pre><code><span class="number">2014</span>-<span class="number">04</span>-<span class="number">02</span> <span class="number">12</span>:<span class="number">24</span>:<span class="number">33</span>,<span class="number">464</span> INFO org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.hdfs</span><span class="class">.server</span><span class="class">.blockmanagement</span><span class="class">.HeartbeatManager</span>: Setting heartbeat recheck interval to <span class="number">30000</span> since dfs<span class="class">.namenode</span><span class="class">.stale</span><span class="class">.datanode</span><span class="class">.interval</span> is less than dfs<span class="class">.namenode</span><span class="class">.heartbeat</span><span class="class">.recheck-interval</span> 
预计检测时间是=<span class="number">2</span>*<span class="number">20</span>+<span class="number">10</span>*<span class="number">3</span>=<span class="number">70</span>，结果发现一台DN down了后，NN检测到的时间还是超过了<span class="number">70</span>秒，最终标记DN为dead的时间是<span class="number">660</span>秒，也就是说这项配置根本就没起作用。接下来我把rechekc的参数设置成<span class="number">100000</span>（也就是<span class="number">100</span>秒），最终发现NN检测到DN挂了确实是用了<span class="number">2</span>*<span class="number">100</span>+<span class="number">10</span>*<span class="number">3</span> = <span class="number">230</span>秒。接下来再来解决第一个疑问， 看看什么是dfs<span class="class">.namenode</span><span class="class">.stale</span><span class="class">.datanode</span><span class="class">.interval</span>，这里引进了一个状态叫做“stale”

DataNodes are marked as stale <span class="keyword">if</span> it does not send heartbeat message to NameNode within the timeout configured using the configuration parameter <span class="string">"dfs.namenode.stale.datanode.interval"</span> <span class="keyword">in</span> seconds (default value is <span class="number">30</span> seconds). 

dfs<span class="class">.namenode</span><span class="class">.stale</span><span class="class">.datanode</span><span class="class">.interval</span> = <span class="number">30000</span>
</code></pre><p>而且默认情况下这个stale特性是关闭的，还需要把<br>    dfs.namenode.check.stale.datanode = true<br>只有把这两项都配置上去，再结合上面的heartbeat才能正常work，否则的话就把dfs.heartbeat.recheck.<br>    interval设置成30秒以上吧。因为如果时间太多，那么对于NN来说是要不断更新状态的，负载太高。可以看一段dfs.namenode.stale.datanode.interval的说明</p>
<pre><code>Default <span class="built_in">time</span> interval <span class="keyword">for</span> marking <span class="operator">a</span> datanode <span class="keyword">as</span> <span class="string">"stale"</span>, i.e., <span class="keyword">if</span> <span class="operator">the</span> namenode has <span class="operator">not</span> received heartbeat msg <span class="built_in">from</span> <span class="operator">a</span> datanode <span class="keyword">for</span> more than this <span class="built_in">time</span> interval, <span class="operator">the</span> datanode will be marked <span class="operator">and</span> treated <span class="keyword">as</span> <span class="string">"stale"</span> <span class="keyword">by</span> default. The stale interval cannot be too small since otherwise this may cause too frequent change <span class="operator">of</span> stale states. We thus <span class="built_in">set</span> <span class="operator">a</span> minimum stale interval <span class="built_in">value</span> (<span class="operator">the</span> default <span class="built_in">value</span> is <span class="number">3</span> times <span class="operator">of</span> heartbeat interval) <span class="operator">and</span> guarantee that <span class="operator">the</span> stale interval cannot be less than <span class="operator">the</span> minimum <span class="built_in">value</span>. A stale data node is avoided during lease/block recovery. It can be conditionally avoided <span class="keyword">for</span> reads (see dfs.namenode.avoid.<span class="built_in">read</span>.stale.datanode) <span class="operator">and</span> <span class="keyword">for</span> writes (see dfs.namenode.avoid.<span class="built_in">write</span>.stale.datanode).
</code></pre>
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://linrunzhang.github.io/2015/11/26/hadoop-heatbeats/" data-id="cihfto8mz0000h6ynt1oouqwr" class="article-share-link" data-share="baidu" data-title="hadoop heatbeats">分享到</a>
      

      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/26/hello-world/" class="article-date">
  <time datetime="2015-11-26T02:10:10.000Z" itemprop="datePublished">2015-11-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/26/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2><h3 id="Create_a_new_post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://linrunzhang.github.io/2015/11/26/hello-world/" data-id="cihfto8o30003h6ynsa9i4lbm" class="article-share-link" data-share="baidu" data-title="Hello World">分享到</a>
      

      

      
    </footer>
  </div>
  
</article>


  
  
</section>
      
      <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a><span class="tag-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/hadoop-deep-learning/" style="font-size: 10px;">hadoop deep learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/11/26/hadoop-读写分析/">hadoop 读写分析</a>
          </li>
        
          <li>
            <a href="/2015/11/26/hadoop-heatbeats/">hadoop heatbeats</a>
          </li>
        
          <li>
            <a href="/2015/11/26/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="http://linrunzhang.github.io" target="_blank">作者</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 <a href="http://linrunzhang.github.io" target="_blank">linrunzhang<br></a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="返回顶部"><img src="/img/scrollup.png"/></a>
</div>

<!-- totop end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>
  function SetShareData(cmd, config) {
    if (shareDataTitle && shareDataUrl) {
      config.bdText = shareDataTitle;
      config.bdUrl = shareDataUrl;
    }
    return config;
  }
  window._bd_share_config={
    "common":{onBeforeClick: SetShareData},
    "share":{"bdCustomStyle":"/css/bdshare.css"}
  };
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="http://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script src="/js/script.js" type="text/javascript"></script>

</div>
</body>
</html>
