
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>hadoop 读写分析 | FrankLin&#39;s World</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、文件的打开

 
1.1、客户端HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：
public FSDataInputStream open(Path f, int bufferSize) throws IOException {
return new DFSClient.DFSDataInp">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop 读写分析">
<meta property="og:url" content="http://linrunzhang.github.io/2015/11/26/hadoop-读写分析/index.html">
<meta property="og:site_name" content="FrankLin's World">
<meta property="og:description" content="一、文件的打开

 
1.1、客户端HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：
public FSDataInputStream open(Path f, int bufferSize) throws IOException {
return new DFSClient.DFSDataInp">
<meta property="og:image" content="http://linrunzhang.github.io/img/hadoop_read.png">
<meta property="og:image" content="http://linrunzhang.github.io/img/hadoop_write.png">
<meta property="og:updated_time" content="2015-11-26T06:02:15.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hadoop 读写分析">
<meta name="twitter:description" content="一、文件的打开

 
1.1、客户端HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：
public FSDataInputStream open(Path f, int bufferSize) throws IOException {
return new DFSClient.DFSDataInp">
  
    <link rel="alternative" href="/atom.xml" title="FrankLin&#39;s World" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
</head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">FrankLin&#39;s World</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="linrunzhang.github.io">
        </form>
      </div>
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main"><article id="post-hadoop-读写分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/26/hadoop-读写分析/" class="article-date">
  <time datetime="2015-11-26T05:32:27.000Z" itemprop="datePublished">2015-11-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      hadoop 读写分析
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、文件的打开</p>
<p><img src="/img/hadoop_read.png" alt="Hadoop Read"></p>
<p><img src="/img/hadoop_write.png" alt="Hadoop Write"> </p>
<p>1.1、客户端<br>HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：</p>
<pre><code><span class="keyword">public</span> FSDataInputStream <span class="built_in">open</span>(Path f, <span class="built_in">int</span> bufferSize) <span class="keyword">throws</span> IOException {
<span class="keyword">return</span> <span class="keyword">new</span> DFSClient.DFSDataInputStream(
dfs.<span class="built_in">open</span>(getPathName(f), bufferSize, verifyChecksum, statistics));
}
</code></pre><p>其中dfs为DistributedFileSystem的成员变量DFSClient，其open函数被调用，其中创建一个DFSInputStream(src, buffersize, verifyChecksum)并返回。</p>
<p>在DFSInputStream的构造函数中，openInfo函数被调用，其主要从namenode中得到要打开的文件所对应的blocks的信息，实现如下：</p>
<pre><code><span class="keyword">synchronized</span> <span class="function"><span class="keyword">void</span> <span class="title">openInfo</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>{

LocatedBlocks newInfo = callGetBlockLocations(namenode, src, <span class="number">0</span>, prefetchSize);
<span class="keyword">this</span>.locatedBlocks = newInfo;
<span class="keyword">this</span>.currentNode = <span class="keyword">null</span>;
}

<span class="keyword">private</span> <span class="keyword">static</span> <span class="function">LocatedBlocks <span class="title">callGetBlockLocations</span><span class="params">(ClientProtocol namenode,

String src, <span class="keyword">long</span> start, <span class="keyword">long</span> length)</span> <span class="keyword">throws</span> IOException </span>{

<span class="function"><span class="keyword">return</span> namenode.<span class="title">getBlockLocations</span><span class="params">(src, start, length)</span></span>;

}
</code></pre><p>LocatedBlocks主要包含一个链表的List<locatedblock> blocks，其中每个LocatedBlock包含如下信息：</locatedblock></p>
<p>Block b：此block的信息<br>long offset：此block在文件中的偏移量<br>DatanodeInfo[] locs：此block位于哪些DataNode上<br>上面namenode.getBlockLocations是一个RPC调用，最终调用NameNode类的getBlockLocations函数。</p>
<p>1.2、NameNode<br>NameNode.getBlockLocations实现如下：</p>
<pre><code><span class="keyword">public</span> <span class="function">LocatedBlocks   <span class="title">getBlockLocations</span><span class="params">(String src,<span class="keyword">long</span> offset,<span class="keyword">long</span> length)</span> <span class="keyword">throws</span> IOException </span>{

    <span class="keyword">return</span> namesystem.getBlockLocations(getClientMachine(),src, offset, length);
}
</code></pre><p>namesystem是NameNode一个成员变量，其类型为FSNamesystem，保存的是NameNode的name space树，其中一个重要的成员变量为FSDirectory dir。</p>
<p>FSDirectory和Lucene中的FSDirectory没有任何关系，其主要包括FSImage fsImage，用于读写硬盘上的fsimage文件，FSImage类有成员变量FSEditLog editLog，用于读写硬盘上的edit文件，这两个文件的关系在上一篇文章中已经解释过。</p>
<p>FSDirectory还有一个重要的成员变量INodeDirectoryWithQuota rootDir，INodeDirectoryWithQuota的父类为INodeDirectory，实现如下：</p>
<pre><code>public <span class="class"><span class="keyword">class</span> <span class="title">INodeDirectory</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">INode</span> {</span>

 ……

<span class="keyword">private</span> <span class="type">List</span>&lt;<span class="type">INode</span>&gt; children;

 ……

｝
</code></pre><p>由此可见INodeDirectory本身是一个INode，其中包含一个链表的INode，此链表中，如果仍为文件夹，则是类型INodeDirectory，如果是文件，则是类型INodeFile，INodeFile中有成员变量BlockInfo blocks[]，是此文件包含的block的信息。显然这是一棵树形的结构。</p>
<p>FSNamesystem.getBlockLocations函数如下：</p>
<pre><code><span class="keyword">public</span> <span class="function">LocatedBlocks <span class="title">getBlockLocations</span><span class="params">(String src, <span class="keyword">long</span> offset, <span class="keyword">long</span> length,

<span class="keyword">boolean</span> doAccessTime)</span> <span class="keyword">throws</span> IOException </span>{

<span class="keyword">final</span> LocatedBlocks ret = getBlockLocationsInternal(src, dir.getFileINode(src),

                 offset, length, Integer.MAX_VALUE, doAccessTime); 
<span class="keyword">return</span> ret;

}
</code></pre><p>dir.getFileINode(src)通过路径名从文件系统树中找到INodeFile，其中保存的是要打开的文件的INode的信息。</p>
<p>getBlockLocationsInternal的实现如下：</p>
<pre><code>  private synchronized LocatedBlocks getBlockLocationsInternal(<span class="keyword">String </span>src,

                                                   INodeFile inode,

                                                   long offset,

                                                   long length,

                                                   int nrBlocksToReturn,

                                                   <span class="keyword">boolean </span>doAccessTime)

                                                   throws IOException {

    //得到此文件的<span class="keyword">block信息
</span>
    <span class="keyword">Block[] </span><span class="keyword">blocks </span>= inode.getBlocks()<span class="comment">;</span>

    List&lt;LocatedBlock&gt; results = new ArrayList&lt;LocatedBlock&gt;(<span class="keyword">blocks.length);
</span>
    //计算从offset开始，长度为length所涉及的<span class="keyword">blocks
</span>
    int curBlk = <span class="number">0</span><span class="comment">;</span>

    long curPos = <span class="number">0</span>, <span class="keyword">blkSize </span>= <span class="number">0</span><span class="comment">;</span>

    int nrBlocks = (<span class="keyword">blocks[0].getNumBytes() </span>== <span class="number">0</span>) ? <span class="number">0</span> : <span class="keyword">blocks.length;
</span>
    for (curBlk = <span class="number">0</span><span class="comment">; curBlk &lt; nrBlocks; curBlk++) {</span>

      <span class="keyword">blkSize </span>= <span class="keyword">blocks[curBlk].getNumBytes();
</span>
      <span class="preprocessor">if</span> (curPos + <span class="keyword">blkSize </span>&gt; offset) {

        //当offset在curPos和curPos + <span class="keyword">blkSize之间的时候，curBlk指向offset所在的block
</span>
        <span class="keyword">break;
</span>
      }

      curPos += <span class="keyword">blkSize;
</span>
    }

    long endOff = offset + length<span class="comment">;</span>

//循环，依次遍历从curBlk开始的每个<span class="keyword">block，直到当前位置curPos越过endOff
</span>
  do {

  int numNodes = <span class="keyword">blocksMap.numNodes(blocks[curBlk]);
</span>
  int numCorruptNodes = countNodes(<span class="keyword">blocks[curBlk]).corruptReplicas();
</span>
  int numCorruptReplicas = corruptReplicas.numCorruptReplicas(<span class="keyword">blocks[curBlk]);
</span>
  <span class="keyword">boolean </span><span class="keyword">blockCorrupt </span>= (numCorruptNodes == numNodes)<span class="comment">;</span>

  int numMachineSet = <span class="keyword">blockCorrupt </span>? numNodes :

                        (numNodes - numCorruptNodes)<span class="comment">;</span>

  //依次找到此<span class="keyword">block所对应的datanode，将其中没有损坏的放入machineSet中
</span>
  DatanodeDescriptor[] machineSet = new DatanodeDescriptor[numMachineSet]<span class="comment">;</span>

  <span class="preprocessor">if</span> (numMachineSet &gt; <span class="number">0</span>) {

    numNodes = <span class="number">0</span><span class="comment">;</span>

    for(<span class="keyword">Iterator&lt;DatanodeDescriptor&gt; </span><span class="keyword">it </span>=

        <span class="keyword">blocksMap.nodeIterator(blocks[curBlk]); </span><span class="keyword">it.hasNext();) </span>{

      DatanodeDescriptor <span class="preprocessor">dn</span> = <span class="keyword">it.next();
</span>
      <span class="keyword">boolean </span>replicaCorrupt = corruptReplicas.isReplicaCorrupt(<span class="keyword">blocks[curBlk], </span><span class="preprocessor">dn</span>)<span class="comment">;</span>

      <span class="preprocessor">if</span> (<span class="keyword">blockCorrupt </span><span class="title">||</span> (!<span class="keyword">blockCorrupt </span>&amp;&amp; !replicaCorrupt))

        machineSet[numNodes++] = <span class="preprocessor">dn</span><span class="comment">;</span>

    }

  }

  //使用此machineSet和当前的<span class="keyword">block构造一个LocatedBlock
</span>
  results.<span class="keyword">add(new </span>LocatedBlock(<span class="keyword">blocks[curBlk], </span>machineSet, curPos,

              <span class="keyword">blockCorrupt));
</span>
  curPos += <span class="keyword">blocks[curBlk].getNumBytes();
</span>
  curBlk++<span class="comment">;</span>

  } <span class="preprocessor">while</span> (curPos &lt; endOff

      &amp;&amp; curBlk &lt; <span class="keyword">blocks.length
</span>
      &amp;&amp; results.size() &lt; nrBlocksToReturn)<span class="comment">;</span>

    //使用此LocatedBlock链表构造一个LocatedBlocks对象返回

    return inode.createLocatedBlocks(results)<span class="comment">;</span>

  }
</code></pre><p>1.3、客户端<br>通过RPC调用，在NameNode得到的LocatedBlocks对象，作为成员变量构造DFSInputStream对象，最后包装为FSDataInputStream返回给用户。</p>
<p>二、文件的读取<br>2.1、客户端<br>文件读取的时候，客户端利用文件打开的时候得到的FSDataInputStream.read(long position, byte[] buffer, int offset, int length)函数进行文件读操作。</p>
<p>FSDataInputStream会调用其封装的DFSInputStream的read(long position, byte[] buffer, int offset, int length)函数，实现如下：</p>
<pre><code><span class="keyword">public</span> <span class="function"><span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">byte</span>[] buffer, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span>

  <span class="keyword">throws</span> IOException </span>{

  <span class="keyword">long</span> filelen = getFileLength();

  <span class="keyword">int</span> realLen = length;

  <span class="keyword">if</span> ((position + length) &gt; filelen) {

    realLen = (<span class="keyword">int</span>)(filelen - position);

  }

  <span class="comment">//首先得到包含从offset到offset + length内容的block列表</span>

  <span class="comment">//比如对于64M一个block的文件系统来说，欲读取从100M开始，长度为128M的数据，则block列表包括第2，3，4块block</span>

  List&lt;LocatedBlock&gt; blockRange = getBlockRange(position, realLen);

  <span class="keyword">int</span> remaining = realLen;

  <span class="comment">//对每一个block，从中读取内容</span>

  <span class="comment">//对于上面的例子，对于第2块block，读取从36M开始，读取长度28M，对于第3块，读取整一块64M，对于第4块，读取从0开始，长度为36M，共128M数据</span>

  <span class="keyword">for</span> (LocatedBlock blk : blockRange) {

    <span class="keyword">long</span> targetStart = position - blk.getStartOffset();

    <span class="keyword">long</span> bytesToRead = Math.min(remaining, blk.getBlockSize() - targetStart);

    fetchBlockByteRange(blk, targetStart,

                        targetStart + bytesToRead - <span class="number">1</span>, buffer, offset);

    remaining -= bytesToRead;

    position += bytesToRead;

    offset += bytesToRead;

  }

  <span class="keyword">assert</span> remaining == <span class="number">0</span> : <span class="string">"Wrong number of bytes read."</span>;

  <span class="keyword">if</span> (stats != <span class="keyword">null</span>) {

    stats.incrementBytesRead(realLen);

  }

  <span class="keyword">return</span> realLen;

}
</code></pre><p>其中getBlockRange函数如下：</p>
<pre><code><span class="label">private</span> synchronized List&lt;LocatedBlock&gt; getBlockRange(long offset,

                                                      long length)

                                                    throws IOException {

  List&lt;LocatedBlock&gt; <span class="keyword">blockRange </span>= new ArrayList&lt;LocatedBlock&gt;()<span class="comment">;</span>

  //首先从缓存的locatedBlocks中查找offset所在的<span class="keyword">block在缓存链表中的位置
</span>
  int <span class="keyword">blockIdx </span>= locatedBlocks.findBlock(offset)<span class="comment">;</span>

  <span class="preprocessor">if</span> (<span class="keyword">blockIdx </span>&lt; <span class="number">0</span>) { // <span class="keyword">block </span>is not cached

    <span class="keyword">blockIdx </span>= LocatedBlocks.getInsertIndex(<span class="keyword">blockIdx);
</span>
  }

  long remaining = length<span class="comment">;</span>

  long curOff = offset<span class="comment">;</span>

  <span class="preprocessor">while</span>(remaining &gt; <span class="number">0</span>) {

    LocatedBlock <span class="keyword">blk </span>= null<span class="comment">;</span>

    //按照<span class="keyword">blockIdx的位置找到block
</span>
    <span class="preprocessor">if</span>(<span class="keyword">blockIdx </span>&lt; locatedBlocks.locatedBlockCount())

      <span class="keyword">blk </span>= locatedBlocks.get(<span class="keyword">blockIdx);
</span>
    //如果<span class="keyword">block为空，则缓存中没有此block，则直接从NameNode中查找这些block，并加入缓存
</span>
    <span class="preprocessor">if</span> (<span class="keyword">blk </span>== null <span class="title">||</span> curOff &lt; <span class="keyword">blk.getStartOffset()) </span>{

      LocatedBlocks newBlocks<span class="comment">;</span>

      newBlocks = callGetBlockLocations(namenode, src, curOff, remaining)<span class="comment">;</span>

      locatedBlocks.insertRange(<span class="keyword">blockIdx, </span>newBlocks.getLocatedBlocks())<span class="comment">;</span>

      continue<span class="comment">;</span>

    }

    //如果<span class="keyword">block找到，则放入结果集
</span>
    <span class="keyword">blockRange.add(blk);
</span>
    long <span class="keyword">bytesRead </span>= <span class="keyword">blk.getStartOffset() </span>+ <span class="keyword">blk.getBlockSize() </span>- curOff<span class="comment">;</span>

    remaining -= <span class="keyword">bytesRead;
</span>
    curOff += <span class="keyword">bytesRead;
</span>
    //取下一个<span class="keyword">block
</span>
    <span class="keyword">blockIdx++;
</span>
  }

  return <span class="keyword">blockRange;
</span>
}
</code></pre><p>其中fetchBlockByteRange实现如下：<br>        private void fetchBlockByteRange(LocatedBlock block, long start,</p>
<pre><code>                                 long <span class="preprocessor">end</span>, <span class="keyword">byte[] </span><span class="keyword">buf, </span>int offset) throws IOException {

  Socket <span class="preprocessor">dn</span> = null<span class="comment">;</span>

  int numAttempts = <span class="keyword">block.getLocations().length;
</span>
  //此<span class="preprocessor">while</span>循环为读取失败后的重试次数

  <span class="preprocessor">while</span> (<span class="preprocessor">dn</span> == null &amp;&amp; numAttempts-- &gt; <span class="number">0</span> ) {

    //选择一个DataNode来读取数据

    DNAddrPair retval = chooseDataNode(<span class="keyword">block);
</span>
    DatanodeInfo chosenNode = retval.info<span class="comment">;</span>

    InetSocketAddress targetAddr = retval.<span class="keyword">addr;
</span>
    <span class="keyword">BlockReader </span>reader = null<span class="comment">;</span>

    try {

      //创建Socket连接到DataNode

      <span class="preprocessor">dn</span> = socketFactory.createSocket()<span class="comment">;</span>

      <span class="preprocessor">dn</span>.connect(targetAddr, socketTimeout)<span class="comment">;</span>

      <span class="preprocessor">dn</span>.setSoTimeout(socketTimeout)<span class="comment">;</span>

      int len = (int) (<span class="preprocessor">end</span> - start + <span class="number">1</span>)<span class="comment">;</span>

      //利用建立的Socket链接，生成一个reader负责从DataNode读取数据

      reader = <span class="keyword">BlockReader.newBlockReader(dn, </span>src,

                                          <span class="keyword">block.getBlock().getBlockId(),
</span>
                                          <span class="keyword">block.getBlock().getGenerationStamp(),
</span>
                                          start, len, <span class="keyword">buffersize,
</span>
                                          verifyChecksum, clientName)<span class="comment">;</span>

      //读取数据

      int nread = reader.readAll(<span class="keyword">buf, </span>offset, len)<span class="comment">;</span>

      return<span class="comment">;</span>

    } finally {

      IOUtils.closeStream(reader)<span class="comment">;</span>

      IOUtils.closeSocket(<span class="preprocessor">dn</span>)<span class="comment">;</span>

      <span class="preprocessor">dn</span> = null<span class="comment">;</span>

    }

    //如果读取失败，则将此DataNode标记为失败节点

    <span class="keyword">addToDeadNodes(chosenNode);
</span>
  }

}
</code></pre><p>BlockReader.newBlockReader函数实现如下：</p>
<pre><code><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> BlockReader <span class="title">newBlockReader</span>(<span class="params"> Socket sock, String file,

                                   <span class="keyword">long</span> blockId,

                                   <span class="keyword">long</span> genStamp,

                                   <span class="keyword">long</span> startOffset, <span class="keyword">long</span> len,

                                   <span class="keyword">int</span> bufferSize, boolean verifyChecksum,

                                   String clientName</span>)

                                   throws IOException </span>{

  <span class="comment">//使用Socket建立写入流，向DataNode发送读指令</span>

  DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

    <span class="keyword">new</span> BufferedOutputStream(NetUtils.getOutputStream(sock,HdfsConstants.WRITE_TIMEOUT)));

  <span class="keyword">out</span>.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

  <span class="keyword">out</span>.write( DataTransferProtocol.OP_READ_BLOCK );

  <span class="keyword">out</span>.writeLong( blockId );

  <span class="keyword">out</span>.writeLong( genStamp );

  <span class="keyword">out</span>.writeLong( startOffset );

  <span class="keyword">out</span>.writeLong( len );

  Text.writeString(<span class="keyword">out</span>, clientName);

  <span class="keyword">out</span>.flush();

  <span class="comment">//使用Socket建立读入流，用于从DataNode读取数据</span>

  DataInputStream <span class="keyword">in</span> = <span class="keyword">new</span> DataInputStream(

      <span class="keyword">new</span> BufferedInputStream(NetUtils.getInputStream(sock),

                              bufferSize));

  DataChecksum checksum = DataChecksum.newDataChecksum( <span class="keyword">in</span> );

  <span class="keyword">long</span> firstChunkOffset = <span class="keyword">in</span>.readLong();

  <span class="comment">//生成一个reader，主要包含读入流，用于读取数据</span>

  <span class="keyword">return</span> <span class="keyword">new</span> BlockReader( file, blockId, <span class="keyword">in</span>, checksum, verifyChecksum,

                          startOffset, firstChunkOffset, sock );

}
</code></pre><p>BlockReader的readAll函数就是用上面生成的DataInputStream读取数据。</p>
<p>2.2、DataNode<br>在DataNode启动的时候，会调用函数startDataNode，其中与数据读取有关的逻辑如下：</p>
<pre><code><span class="function"><span class="keyword">void</span> <span class="title">startDataNode</span><span class="params">(Configuration conf,

                   AbstractList&lt;File&gt; dataDirs

                   )</span> <span class="keyword">throws</span> IOException </span>{

  ……

  <span class="comment">// 建立一个ServerSocket，并生成一个DataXceiverServer来监控客户端的链接</span>

  ServerSocket ss = (socketWriteTimeout &gt; <span class="number">0</span>) ?

        ServerSocketChannel.open().socket() : <span class="keyword">new</span> ServerSocket();

  Server.bind(ss, socAddr, <span class="number">0</span>);

  ss.setReceiveBufferSize(DEFAULT_DATA_SOCKET_SIZE);

  <span class="comment">// adjust machine name with the actual port</span>

  tmpPort = ss.getLocalPort();

  selfAddr = <span class="keyword">new</span> InetSocketAddress(ss.getInetAddress().getHostAddress(),

                                   tmpPort);

  <span class="keyword">this</span>.dnRegistration.setName(machineName + <span class="string">":"</span> + tmpPort);

  <span class="keyword">this</span>.threadGroup = <span class="keyword">new</span> ThreadGroup(<span class="string">"dataXceiverServer"</span>);

  <span class="keyword">this</span>.dataXceiverServer = <span class="keyword">new</span> Daemon(threadGroup,

      <span class="keyword">new</span> DataXceiverServer(ss, conf, <span class="keyword">this</span>));

  <span class="keyword">this</span>.threadGroup.setDaemon(<span class="keyword">true</span>); <span class="comment">// auto destroy when empty</span>

  ……

}   
</code></pre><p>DataXceiverServer.run()函数如下：</p>
<pre><code><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>{

  <span class="keyword">while</span> (datanode.shouldRun) {

      <span class="comment">//接受客户端的链接</span>

      Socket s = ss.accept();

      s.setTcpNoDelay(<span class="keyword">true</span>);

      <span class="comment">//生成一个线程DataXceiver来对建立的链接提供服务</span>

      <span class="keyword">new</span> Daemon(datanode.threadGroup,

          <span class="keyword">new</span> DataXceiver(s, datanode, <span class="keyword">this</span>)).start();

  }

  <span class="keyword">try</span> {

    ss.close();

  } <span class="keyword">catch</span> (IOException ie) {

    LOG.warn(datanode.dnRegistration + <span class="string">":DataXceiveServer: "</span>

                            + StringUtils.stringifyException(ie));

  }

}
</code></pre><p>DataXceiver.run()函数如下：</p>
<pre><code><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span>(<span class="params"></span>) </span>{

  DataInputStream <span class="keyword">in</span>=<span class="keyword">null</span>;

  <span class="keyword">try</span> {

    <span class="comment">//建立一个输入流，读取客户端发送的指令</span>

    <span class="keyword">in</span> = <span class="keyword">new</span> DataInputStream(

        <span class="keyword">new</span> BufferedInputStream(NetUtils.getInputStream(s),

                                SMALL_BUFFER_SIZE));

    <span class="keyword">short</span> version = <span class="keyword">in</span>.readShort();

    boolean local = s.getInetAddress().equals(s.getLocalAddress());

    <span class="keyword">byte</span> op = <span class="keyword">in</span>.readByte();

    <span class="comment">// Make sure the xciver count is not exceeded</span>

    <span class="keyword">int</span> curXceiverCount = datanode.getXceiverCount();

    <span class="keyword">long</span> startTime = DataNode.now();

    <span class="keyword">switch</span> ( op ) {

    <span class="comment">//读取</span>

    <span class="keyword">case</span> DataTransferProtocol.OP_READ_BLOCK:

      <span class="comment">//真正的读取数据</span>

      readBlock( <span class="keyword">in</span> );

      datanode.myMetrics.readBlockOp.inc(DataNode.now() - startTime);

      <span class="keyword">if</span> (local)

        datanode.myMetrics.readsFromLocalClient.inc();

      <span class="keyword">else</span>

        datanode.myMetrics.readsFromRemoteClient.inc();

      <span class="keyword">break</span>;

    <span class="comment">//写入</span>

    <span class="keyword">case</span> DataTransferProtocol.OP_WRITE_BLOCK:

      <span class="comment">//真正的写入数据</span>

      writeBlock( <span class="keyword">in</span> );

      datanode.myMetrics.writeBlockOp.inc(DataNode.now() - startTime);

      <span class="keyword">if</span> (local)

        datanode.myMetrics.writesFromLocalClient.inc();

      <span class="keyword">else</span>

        datanode.myMetrics.writesFromRemoteClient.inc();

      <span class="keyword">break</span>;

    <span class="comment">//其他的指令</span>

    ……

    }

  } <span class="keyword">catch</span> (Throwable t) {

    LOG.error(datanode.dnRegistration + <span class="string">":DataXceiver"</span>,t);

  } <span class="keyword">finally</span> {

    IOUtils.closeStream(<span class="keyword">in</span>);

    IOUtils.closeSocket(s);

    dataXceiverServer.childSockets.remove(s);

  }

}



<span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readBlock</span>(<span class="params">DataInputStream <span class="keyword">in</span></span>) throws IOException </span>{

  <span class="comment">//读取指令</span>

  <span class="keyword">long</span> blockId = <span class="keyword">in</span>.readLong();         

  Block block = <span class="keyword">new</span> Block( blockId, <span class="number">0</span> , <span class="keyword">in</span>.readLong());

  <span class="keyword">long</span> startOffset = <span class="keyword">in</span>.readLong();

  <span class="keyword">long</span> length = <span class="keyword">in</span>.readLong();

  String clientName = Text.readString(<span class="keyword">in</span>);

  <span class="comment">//创建一个写入流，用于向客户端写数据</span>

  OutputStream baseStream = NetUtils.getOutputStream(s,

      datanode.socketWriteTimeout);

  DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

               <span class="keyword">new</span> BufferedOutputStream(baseStream, SMALL_BUFFER_SIZE));

  <span class="comment">//生成BlockSender用于读取本地的block的数据，并发送给客户端</span>

  <span class="comment">//BlockSender有一个成员变量InputStream blockIn用于读取本地block的数据</span>

  BlockSender blockSender = <span class="keyword">new</span> BlockSender(block, startOffset, length,

          <span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">false</span>, datanode, clientTraceFmt);

   <span class="keyword">out</span>.writeShort(DataTransferProtocol.OP_STATUS_SUCCESS); <span class="comment">// send op status</span>

   <span class="comment">//向客户端写入数据</span>

   <span class="keyword">long</span> read = blockSender.sendBlock(<span class="keyword">out</span>, baseStream, <span class="keyword">null</span>);

   ……

  } <span class="keyword">finally</span> {

    IOUtils.closeStream(<span class="keyword">out</span>);

    IOUtils.closeStream(blockSender);

  }

}
</code></pre><p>三、文件的写入<br>下面解析向hdfs上传一个文件的过程。</p>
<p>3.1、客户端<br>上传一个文件到hdfs，一般会调用DistributedFileSystem.create，其实现如下：</p>
<pre><code><span class="keyword">public</span> <span class="function">FSDataOutputStream <span class="title">create</span><span class="params">(Path f, FsPermission permission,

  <span class="keyword">boolean</span> overwrite,

  <span class="keyword">int</span> bufferSize, <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize,

  Progressable progress)</span> <span class="keyword">throws</span> IOException </span>{

  <span class="keyword">return</span> <span class="keyword">new</span> FSDataOutputStream

     (dfs.create(getPathName(f), permission,

                 overwrite, replication, blockSize, progress, bufferSize),

      statistics);

}
</code></pre><p>其最终生成一个FSDataOutputStream用于向新生成的文件中写入数据。其成员变量dfs的类型为DFSClient，DFSClient的create函数如下：</p>
<pre><code>  public <span class="type">OutputStream</span> create(<span class="type">String</span> src,

                           <span class="type">FsPermission</span> permission,

                           boolean overwrite,

                           short replication,

                           long blockSize,

                           <span class="type">Progressable</span> progress,

                           <span class="type">int</span> buffersize

                           ) throws <span class="type">IOException</span> {

  checkOpen();

  <span class="keyword">if</span> (permission == null) {

    permission = <span class="type">FsPermission</span>.getDefault();

  }

  <span class="type">FsPermission</span> masked = permission.applyUMask(<span class="type">FsPermission</span>.getUMask(conf));

  <span class="type">OutputStream</span> <span class="literal">result</span> = new <span class="type">DFSOutputStream</span>(src, masked,

      overwrite, replication, blockSize, progress, buffersize,

      conf.getInt(<span class="string">"io.bytes.per.checksum"</span>, <span class="number">512</span>));

  leasechecker.put(src, <span class="literal">result</span>);

  <span class="keyword">return</span> <span class="literal">result</span>;

}
</code></pre><p>其中构造了一个DFSOutputStream，在其构造函数中，同过RPC调用NameNode的create来创建一个文件。<br>当然，构造函数中还做了一件重要的事情，就是streamer.start()，也即启动了一个pipeline，用于写数据，在写入数据的过程中，我们会仔细分析。</p>
<pre><code>DFSOutputStream(String src, FsPermission masked, <span class="keyword">boolean</span> overwrite,

  <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, Progressable progress,

  <span class="keyword">int</span> buffersize, <span class="keyword">int</span> bytesPerChecksum) <span class="keyword">throws</span> IOException {

<span class="keyword">this</span>(src, blockSize, progress, bytesPerChecksum);

computePacketChunkSize(writePacketSize, bytesPerChecksum);

<span class="keyword">try</span> {

  namenode.create(

      src, masked, clientName, overwrite, replication, blockSize);

} <span class="keyword">catch</span>(RemoteException re) {

  <span class="keyword">throw</span> re.unwrapRemoteException(AccessControlException.<span class="keyword">class</span>,

                                 QuotaExceededException.<span class="keyword">class</span>);

}

streamer.start();

}
</code></pre><p>3.2、NameNode<br>NameNode的create函数调用namesystem.startFile函数，其又调用startFileInternal函数，实现如下：</p>
<pre><code><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> startFileInternal(<span class="keyword">String</span> src,

                                         PermissionStatus permissions,

                                         <span class="keyword">String</span> holder,

                                         <span class="keyword">String</span> clientMachine,

                                         <span class="built_in">boolean</span> overwrite,

                                         <span class="built_in">boolean</span> <span class="built_in">append</span>,

                                         <span class="keyword">short</span> replication,

                                         <span class="keyword">long</span> blockSize

                                         ) <span class="keyword">throws</span> IOException {

   ......

  <span class="comment">//创建一个新的文件，状态为under construction，没有任何data block与之对应</span>

  <span class="keyword">long</span> genstamp = nextGenerationStamp();

  INodeFileUnderConstruction newNode = dir.addFile(src, permissions,

     replication, blockSize, holder, clientMachine, clientNode, genstamp);

  ......

 }
</code></pre><p>3.3、客户端<br>下面轮到客户端向新创建的文件中写入数据了，一般会使用FSDataOutputStream的write函数，最终会调用DFSOutputStream的writeChunk函数：</p>
<p>按照hdfs的设计，对block的数据写入使用的是pipeline的方式，也即将数据分成一个个的package，如果需要复制三分，分别写入DataNode 1, 2, 3，则会进行如下的过程：</p>
<p>首先将package 1写入DataNode 1<br>然后由DataNode 1负责将package 1写入DataNode 2，同时客户端可以将pacage 2写入DataNode 1<br>然后DataNode 2负责将package 1写入DataNode 3, 同时客户端可以讲package 3写入DataNode 1，DataNode 1将package 2写入DataNode 2<br>就这样将一个个package排着队的传递下去，直到所有的数据全部写入并复制完毕<br>          protected synchronized void writeChunk(byte[] b, int offset, int len, byte[] checksum)</p>
<pre><code>                                                    <span class="keyword">throws</span> IOException {

  <span class="comment">//创建一个package，并写入数据</span>

  currentPacket = <span class="keyword">new</span> Packet(packetSize, chunksPerPacket,

                               bytesCurBlock);

  currentPacket.writeChecksum(checksum, <span class="number">0</span>, cklen);

  currentPacket.writeData(b, offset, len);

  currentPacket.numChunks++;

  bytesCurBlock += len;

  <span class="comment">//如果此package已满，则放入队列中准备发送</span>

  <span class="keyword">if</span> (currentPacket.numChunks == currentPacket.maxChunks ||

      bytesCurBlock == blockSize) {

      ......

      dataQueue.addLast(currentPacket);

      <span class="comment">//唤醒等待dataqueue的传输线程，也即DataStreamer</span>

      dataQueue.notifyAll();

      currentPacket = <span class="keyword">null</span>;

      ......

  }

  }


DataStreamer的run函数如下：

  <span class="keyword">public</span> <span class="keyword">void</span> run() {

    <span class="keyword">while</span> (!closed &amp;&amp; clientRunning) {

      Packet one = <span class="keyword">null</span>;

      <span class="keyword">synchronized</span> (dataQueue) {

        <span class="comment">//如果队列中没有package，则等待</span>

        <span class="keyword">while</span> ((!closed &amp;&amp; !hasError &amp;&amp; clientRunning

               &amp;&amp; dataQueue.<span class="keyword">size</span>() == <span class="number">0</span>) || doSleep) {

          <span class="keyword">try</span> {

            dataQueue.wait(<span class="number">1000</span>);

          } <span class="keyword">catch</span> (InterruptedException  e) {

          }

          doSleep = <span class="keyword">false</span>;

        }

        <span class="keyword">try</span> {

          <span class="comment">//得到队列中的第一个package</span>

          one = dataQueue.getFirst();

          <span class="keyword">long</span> offsetInBlock = one.offsetInBlock;

          <span class="comment">//由NameNode分配block，并生成一个写入流指向此block</span>

          <span class="keyword">if</span> (blockStream == <span class="keyword">null</span>) {

            nodes = nextBlockOutputStream(src);

            response = <span class="keyword">new</span> ResponseProcessor(nodes);

            response.start();

          }

          ByteBuffer buf = one.getBuffer();

          <span class="comment">//将package从dataQueue移至ackQueue,等待确认</span>

          dataQueue.removeFirst();

          dataQueue.notifyAll();

          <span class="keyword">synchronized</span> (ackQueue) {

            ackQueue.addLast(one);

            ackQueue.notifyAll();

          }

      <span class="comment">//利用生成的写入流将数据写入DataNode中的block</span>

      blockStream.<span class="keyword">write</span>(buf.array(), buf.position(), buf.remaining());

      <span class="keyword">if</span> (one.lastPacketInBlock) {

        blockStream.writeInt(<span class="number">0</span>); <span class="comment">//表示此block写入完毕</span>

      }

      blockStream.flush();

    } <span class="keyword">catch</span> (Throwable e) {

    }

  }

  ......

 }
</code></pre><p>其中重要的一个函数是nextBlockOutputStream，实现如下：</p>
<pre><code> <span class="keyword">private</span> DatanodeInfo[] nextBlockOutputStream(String client) <span class="keyword">throws</span> IOException {

    LocatedBlock lb = <span class="keyword">null</span>;

    <span class="keyword">boolean</span> retry = <span class="keyword">false</span>;

    DatanodeInfo[] nodes;

    <span class="keyword">int</span> <span class="keyword">count</span> = conf.getInt(<span class="string">"dfs.client.block.write.retries"</span>, <span class="number">3</span>);

    <span class="keyword">boolean</span> success;

    <span class="keyword">do</span> {

      ......

      <span class="comment">//由NameNode为文件分配DataNode和block</span>

      lb = locateFollowingBlock(startTime);

      block = lb.getBlock();

      nodes = lb.getLocations();

      <span class="comment">//创建向DataNode的写入流</span>

      success = createBlockOutputStream(nodes, clientName, <span class="keyword">false</span>);

      ......

    } <span class="keyword">while</span> (retry &amp;&amp; --<span class="keyword">count</span> &gt;= <span class="number">0</span>);

    <span class="keyword">return</span> nodes;

}
</code></pre><p>locateFollowingBlock中通过RPC调用namenode.addBlock(src, clientName)函数</p>
<p>3.4、NameNode<br>NameNode的addBlock函数实现如下：</p>
<pre><code> <span class="keyword">public</span> LocatedBlock addBlock(<span class="keyword">String</span> src,

                           <span class="keyword">String</span> clientName) <span class="keyword">throws</span> IOException {

    LocatedBlock locatedBlock = namesystem.getAdditionalBlock(src, clientName);

    <span class="keyword">return</span> locatedBlock;

  }

FSNamesystem的getAdditionalBlock实现如下：

  <span class="keyword">public</span> LocatedBlock getAdditionalBlock(<span class="keyword">String</span> src,

                                     <span class="keyword">String</span> clientName

                                     ) <span class="keyword">throws</span> IOException {

<span class="keyword">long</span> fileLength, blockSize;

<span class="built_in">int</span> replication;

DatanodeDescriptor clientNode = <span class="keyword">null</span>;

Block newBlock = <span class="keyword">null</span>;

......

<span class="comment">//为新的block选择DataNode</span>

DatanodeDescriptor targets[] = replicator.chooseTarget(replication,

                                                       clientNode,

                                                       <span class="keyword">null</span>,

                                                       blockSize);

......

<span class="comment">//得到文件路径中所有path的INode，其中最后一个是新添加的文件对的INode，状态为under construction</span>

INode[] pathINodes = dir.getExistingPathINodes(src);

<span class="built_in">int</span> inodesLen = pathINodes.length;

INodeFileUnderConstruction pendingFile  = (INodeFileUnderConstruction)

                                            pathINodes[inodesLen - <span class="number">1</span>];

<span class="comment">//为文件分配block, 并设置在那写DataNode上</span>

newBlock = allocateBlock(src, pathINodes);

pendingFile.setTargets(targets);

......

<span class="keyword">return</span> <span class="keyword">new</span> LocatedBlock(newBlock, targets, fileLength);

}
</code></pre><p>3.5、客户端<br>在分配了DataNode和block以后，createBlockOutputStream开始写入数据。</p>
<pre><code>  <span class="function"><span class="keyword">private</span> boolean <span class="title">createBlockOutputStream</span>(<span class="params">DatanodeInfo[] nodes, String client,

                boolean recoveryFlag</span>) </span>{

    <span class="comment">//创建一个socket，链接DataNode</span>

    InetSocketAddress target = NetUtils.createSocketAddr(nodes[<span class="number">0</span>].getName());

    s = socketFactory.createSocket();

    <span class="keyword">int</span> timeoutValue = <span class="number">3000</span> * nodes.length + socketTimeout;

    s.connect(target, timeoutValue);

    s.setSoTimeout(timeoutValue);

    s.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);

    <span class="keyword">long</span> writeTimeout = HdfsConstants.WRITE_TIMEOUT_EXTENSION * nodes.length +

                        datanodeWriteTimeout;

    DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

        <span class="keyword">new</span> BufferedOutputStream(NetUtils.getOutputStream(s, writeTimeout),

                                 DataNode.SMALL_BUFFER_SIZE));

    blockReplyStream = <span class="keyword">new</span> DataInputStream(NetUtils.getInputStream(s));

    <span class="comment">//写入指令</span>

    <span class="keyword">out</span>.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

    <span class="keyword">out</span>.write( DataTransferProtocol.OP_WRITE_BLOCK );

    <span class="keyword">out</span>.writeLong( block.getBlockId() );

    <span class="keyword">out</span>.writeLong( block.getGenerationStamp() );

    <span class="keyword">out</span>.writeInt( nodes.length );

    <span class="keyword">out</span>.writeBoolean( recoveryFlag );

    Text.writeString( <span class="keyword">out</span>, client );

    <span class="keyword">out</span>.writeBoolean(<span class="keyword">false</span>);

    <span class="keyword">out</span>.writeInt( nodes.length - <span class="number">1</span> );

    <span class="comment">//注意，次循环从1开始，而非从0开始。将除了第一个DataNode以外的另外两个DataNode的信息发送给第一个DataNode, 第一个DataNode可以根据此信息将数据写给另两个DataNode</span>

    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nodes.length; i++) {

      nodes[i].write(<span class="keyword">out</span>);

    }

    checksum.writeHeader( <span class="keyword">out</span> );

    <span class="keyword">out</span>.flush();

    firstBadLink = Text.readString(blockReplyStream);

    <span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) {

      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink "</span> + firstBadLink);

    }

    blockStream = <span class="keyword">out</span>;

}
</code></pre><p>客户端在DataStreamer的run函数中创建了写入流后，调用blockStream.write将数据写入DataNode</p>
<p>3.6、DataNode<br>    DataNode的DataXceiver中，收到指令DataTransferProtocol.OP_WRITE_BLOCK则调用writeBlock函数：</p>
<pre><code>    <span class="keyword">private</span> <span class="typename">void</span> writeBlock(DataInputStream <span class="keyword">in</span>) <span class="keyword">throws</span> IOException {

    DatanodeInfo srcDataNode = <span class="literal">null</span>;

    <span class="comment">//读入头信息</span>

    Block block = <span class="keyword">new</span> Block(<span class="keyword">in</span>.readLong(),

        dataXceiverServer.estimateBlockSize, <span class="keyword">in</span>.readLong());

    <span class="typename">int</span> pipelineSize = <span class="keyword">in</span>.readInt(); <span class="comment">// num of datanodes in entire pipeline</span>

    <span class="typename">boolean</span> isRecovery = <span class="keyword">in</span>.readBoolean(); <span class="comment">// is this part of recovery?</span>

    String client = Text.readString(<span class="keyword">in</span>); <span class="comment">// working on behalf of this client</span>

    <span class="typename">boolean</span> hasSrcDataNode = <span class="keyword">in</span>.readBoolean(); <span class="comment">// is src node info present</span>

    <span class="keyword">if</span> (hasSrcDataNode) {

      srcDataNode = <span class="keyword">new</span> DatanodeInfo();

      srcDataNode.readFields(<span class="keyword">in</span>);

    }

    <span class="typename">int</span> numTargets = <span class="keyword">in</span>.readInt();

    <span class="keyword">if</span> (numTargets &lt; <span class="number">0</span>) {

      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Mislabelled incoming datastream."</span>);

    }

    <span class="comment">//读入剩下的DataNode列表，如果当前是第一个DataNode，则此列表中收到的是第二个，第三个DataNode的信息，如果当前是第二个DataNode，则受到的是第三个DataNode的信息</span>

    DatanodeInfo targets[] = <span class="keyword">new</span> DatanodeInfo[numTargets];

    <span class="keyword">for</span> (<span class="typename">int</span> i = <span class="number">0</span>; i &lt; targets.length; i++) {

      DatanodeInfo tmp = <span class="keyword">new</span> DatanodeInfo();

      tmp.readFields(<span class="keyword">in</span>);

      targets[i] = tmp;

    }

    DataOutputStream mirrorOut = <span class="literal">null</span>;  <span class="comment">// stream to next target</span>

    DataInputStream mirrorIn = <span class="literal">null</span>;    <span class="comment">// reply from next target</span>

    DataOutputStream replyOut = <span class="literal">null</span>;   <span class="comment">// stream to prev target</span>

    Socket mirrorSock = <span class="literal">null</span>;           <span class="comment">// socket to next target</span>

    BlockReceiver blockReceiver = <span class="literal">null</span>; <span class="comment">// responsible for data handling</span>

    String mirrorNode = <span class="literal">null</span>;           <span class="comment">// the name:port of next target</span>

    String firstBadLink = <span class="string">""</span>;           <span class="comment">// first datanode that failed in connection setup</span>

    <span class="keyword">try</span> {

      <span class="comment">//生成一个BlockReceiver, 其有成员变量DataInputStream in为从客户端或者上一个DataNode读取数据，还有成员变量DataOutputStream mirrorOut，用于向下一个DataNode写入数据，还有成员变量OutputStream out用于将数据写入本地。</span>

      blockReceiver = <span class="keyword">new</span> BlockReceiver(block, <span class="keyword">in</span>,

          s.getRemoteSocketAddress().toString(),

          s.getLocalSocketAddress().toString(),

          isRecovery, client, srcDataNode, datanode);

      <span class="comment">// get a connection back to the previous target</span>

      replyOut = <span class="keyword">new</span> DataOutputStream(

                     NetUtils.getOutputStream(s, datanode.socketWriteTimeout));

      <span class="comment">//如果当前不是最后一个DataNode，则同下一个DataNode建立socket连接</span>

      <span class="keyword">if</span> (targets.length &gt; <span class="number">0</span>) {

        InetSocketAddress mirrorTarget = <span class="literal">null</span>;

        <span class="comment">// Connect to backup machine</span>

        mirrorNode = targets[<span class="number">0</span>].getName();

        mirrorTarget = NetUtils.createSocketAddr(mirrorNode);

        mirrorSock = datanode.newSocket();

        <span class="typename">int</span> timeoutValue = numTargets * datanode.socketTimeout;

        <span class="typename">int</span> writeTimeout = datanode.socketWriteTimeout +

                             (HdfsConstants.WRITE_TIMEOUT_EXTENSION * numTargets);

        mirrorSock.connect(mirrorTarget, timeoutValue);

        mirrorSock.setSoTimeout(timeoutValue);

        mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);

        <span class="comment">//创建向下一个DataNode写入数据的流</span>

        mirrorOut = <span class="keyword">new</span> DataOutputStream(

             <span class="keyword">new</span> BufferedOutputStream(

                         NetUtils.getOutputStream(mirrorSock, writeTimeout),

                         SMALL_BUFFER_SIZE));

        mirrorIn = <span class="keyword">new</span> DataInputStream(NetUtils.getInputStream(mirrorSock));

        mirrorOut.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

        mirrorOut.write( DataTransferProtocol.OP_WRITE_BLOCK );

        mirrorOut.writeLong( block.getBlockId() );

        mirrorOut.writeLong( block.getGenerationStamp() );

        mirrorOut.writeInt( pipelineSize );

        mirrorOut.writeBoolean( isRecovery );

        Text.writeString( mirrorOut, client );

        mirrorOut.writeBoolean(hasSrcDataNode);

        <span class="keyword">if</span> (hasSrcDataNode) { <span class="comment">// pass src node information</span>

          srcDataNode.write(mirrorOut);

        }

        mirrorOut.writeInt( targets.length - <span class="number">1</span> );

        <span class="comment">//此出也是从1开始，将除了下一个DataNode的其他DataNode信息发送给下一个DataNode</span>

        <span class="keyword">for</span> ( <span class="typename">int</span> i = <span class="number">1</span>; i &lt; targets.length; i++ ) {

          targets[i].write( mirrorOut );

        }

        blockReceiver.writeChecksumHeader(mirrorOut);

        mirrorOut.flush();

      }

      <span class="comment">//使用BlockReceiver接受block</span>

      String mirrorAddr = (mirrorSock == <span class="literal">null</span>) ? null : mirrorNode;

      blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,

                                 mirrorAddr, <span class="literal">null</span>, targets.length);

      ......

    } <span class="keyword">finally</span> {

      <span class="comment">// close all opened streams</span>

      IOUtils.closeStream(mirrorOut);

      IOUtils.closeStream(mirrorIn);

      IOUtils.closeStream(replyOut);

      IOUtils.closeSocket(mirrorSock);

      IOUtils.closeStream(blockReceiver);

    }

    }



BlockReceiver的receiveBlock函数中，一段重要的逻辑如下：

    <span class="typename">void</span> receiveBlock(

      DataOutputStream mirrOut, <span class="comment">// output to next datanode</span>

      DataInputStream mirrIn,   <span class="comment">// input from next datanode</span>

      DataOutputStream replyOut,  <span class="comment">// output to previous datanode</span>

      String mirrAddr, BlockTransferThrottler throttlerArg,

      <span class="typename">int</span> numTargets) <span class="keyword">throws</span> IOException {

      ......

      <span class="comment">//不断的接受package，直到结束</span>

      <span class="keyword">while</span> (receivePacket() &gt; <span class="number">0</span>) {}

      <span class="keyword">if</span> (mirrorOut != <span class="literal">null</span>) {

        <span class="keyword">try</span> {

          mirrorOut.writeInt(<span class="number">0</span>); <span class="comment">// mark the end of the block</span>

          mirrorOut.flush();

        } <span class="keyword">catch</span> (IOException e) {

          handleMirrorOutError(e);

        }

      }

      ......

  }



BlockReceiver的receivePacket函数如下：

     <span class="keyword">private</span> <span class="typename">int</span> receivePacket() <span class="keyword">throws</span> IOException {

    <span class="comment">//从客户端或者上一个节点接收一个package</span>

    <span class="typename">int</span> payloadLen = readNextPacket();

    buf.mark();

    <span class="comment">//read the header</span>

    buf.getInt(); <span class="comment">// packet length</span>

    offsetInBlock = buf.getLong(); <span class="comment">// get offset of packet in block</span>

    <span class="typename">long</span> seqno = buf.getLong();    <span class="comment">// get seqno</span>

    <span class="typename">boolean</span> lastPacketInBlock = (buf.get() != <span class="number">0</span>);

    <span class="typename">int</span> endOfHeader = buf.position();

    buf.reset();

    setBlockPosition(offsetInBlock);

    <span class="comment">//将package写入下一个DataNode</span>

    <span class="keyword">if</span> (mirrorOut != <span class="literal">null</span>) {

      <span class="keyword">try</span> {

        mirrorOut.write(buf.array(), buf.position(), buf.remaining());

        mirrorOut.flush();

      } <span class="keyword">catch</span> (IOException e) {

        handleMirrorOutError(e);

      }

    }

    buf.position(endOfHeader);       

    <span class="typename">int</span> len = buf.getInt();

    offsetInBlock += len;

    <span class="typename">int</span> checksumLen = ((len + bytesPerChecksum - <span class="number">1</span>)/bytesPerChecksum)*

                                                            checksumSize;

    <span class="typename">int</span> checksumOff = buf.position();

    <span class="typename">int</span> dataOff = checksumOff + checksumLen;

    <span class="typename">byte</span> pktBuf[] = buf.array();

    buf.position(buf.limit()); <span class="comment">// move to the end of the data.</span>

    ......

    <span class="comment">//将数据写入本地的block</span>

    out.write(pktBuf, dataOff, len);

    <span class="comment">/// flush entire packet before sending ack</span>

    flush();

    <span class="comment">// put in queue for pending acks</span>

    <span class="keyword">if</span> (responder != <span class="literal">null</span>) {

      ((PacketResponder)responder.getRunnable()).enqueue(seqno,

                                      lastPacketInBlock);

    }

    <span class="keyword">return</span> payloadLen;

    }
</code></pre>
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://linrunzhang.github.io/2015/11/26/hadoop-读写分析/" data-id="cihfu2dzr0004juynmajm3kgr" class="article-share-link" data-share="baidu" data-title="hadoop 读写分析">分享到</a>
      

      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2015/11/26/hadoop-heatbeats/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">hadoop heatbeats</div>
    </a>
  
</nav>

  
</article>

</section>
      
      <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a><span class="tag-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/hadoop-deep-learning/" style="font-size: 10px;">hadoop deep learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/11/26/hadoop-读写分析/">hadoop 读写分析</a>
          </li>
        
          <li>
            <a href="/2015/11/26/hadoop-heatbeats/">hadoop heatbeats</a>
          </li>
        
          <li>
            <a href="/2015/11/26/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="http://linrunzhang.github.io" target="_blank">作者</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 <a href="http://linrunzhang.github.io" target="_blank">linrunzhang<br></a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="返回顶部"><img src="/img/scrollup.png"/></a>
</div>

<!-- totop end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>
  function SetShareData(cmd, config) {
    if (shareDataTitle && shareDataUrl) {
      config.bdText = shareDataTitle;
      config.bdUrl = shareDataUrl;
    }
    return config;
  }
  window._bd_share_config={
    "common":{onBeforeClick: SetShareData},
    "share":{"bdCustomStyle":"/css/bdshare.css"}
  };
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="http://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script src="/js/script.js" type="text/javascript"></script>

</div>
</body>
</html>
