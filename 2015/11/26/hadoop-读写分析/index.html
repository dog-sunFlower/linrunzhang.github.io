
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>hadoop 读写分析 | FrankLin&#39;s World</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、文件的打开

 
1.1、客户端HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：
public FSDataInputStream open(Path f, int bufferSize) throws IOException {
return new DFSClient.DFSDataInp">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop 读写分析">
<meta property="og:url" content="http://linrunzhang.github.io/2015/11/26/hadoop-读写分析/index.html">
<meta property="og:site_name" content="FrankLin's World">
<meta property="og:description" content="一、文件的打开

 
1.1、客户端HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：
public FSDataInputStream open(Path f, int bufferSize) throws IOException {
return new DFSClient.DFSDataInp">
<meta property="og:image" content="https://github.com/linrunzhang/linrunzhang.github.io/blob/master/resource/hadoop_read.png">
<meta property="og:image" content="https://github.com/linrunzhang/linrunzhang.github.io/blob/master/resource/hadoop_write.png">
<meta property="og:updated_time" content="2015-11-26T05:44:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hadoop 读写分析">
<meta name="twitter:description" content="一、文件的打开

 
1.1、客户端HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：
public FSDataInputStream open(Path f, int bufferSize) throws IOException {
return new DFSClient.DFSDataInp">
  
    <link rel="alternative" href="/atom.xml" title="FrankLin&#39;s World" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
</head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">FrankLin&#39;s World</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="linrunzhang.github.io">
        </form>
      </div>
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main"><article id="post-hadoop-读写分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/26/hadoop-读写分析/" class="article-date">
  <time datetime="2015-11-26T05:32:27.000Z" itemprop="datePublished">2015-11-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      hadoop 读写分析
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、文件的打开</p>
<p><img src="https://github.com/linrunzhang/linrunzhang.github.io/blob/master/resource/hadoop_read.png" alt="Hadoop Read"></p>
<p><img src="https://github.com/linrunzhang/linrunzhang.github.io/blob/master/resource/hadoop_write.png" alt="Hadoop Write"> </p>
<p>1.1、客户端<br>HDFS打开一个文件，需要在客户端调用DistributedFileSystem.open(Path f, int bufferSize)，其实现为：</p>
<pre><code><span class="keyword">public</span> FSDataInputStream <span class="built_in">open</span>(Path f, <span class="built_in">int</span> bufferSize) <span class="keyword">throws</span> IOException {
<span class="keyword">return</span> <span class="keyword">new</span> DFSClient.DFSDataInputStream(
dfs.<span class="built_in">open</span>(getPathName(f), bufferSize, verifyChecksum, statistics));
}
</code></pre><p>其中dfs为DistributedFileSystem的成员变量DFSClient，其open函数被调用，其中创建一个DFSInputStream(src, buffersize, verifyChecksum)并返回。</p>
<p>在DFSInputStream的构造函数中，openInfo函数被调用，其主要从namenode中得到要打开的文件所对应的blocks的信息，实现如下：</p>
<pre><code>    <span class="keyword">synchronized</span> <span class="function"><span class="keyword">void</span> <span class="title">openInfo</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>{

    LocatedBlocks newInfo = callGetBlockLocations(namenode, src, <span class="number">0</span>, prefetchSize);
    <span class="keyword">this</span>.locatedBlocks = newInfo;
    <span class="keyword">this</span>.currentNode = <span class="keyword">null</span>;
    }

<span class="keyword">private</span> <span class="keyword">static</span> <span class="function">LocatedBlocks <span class="title">callGetBlockLocations</span><span class="params">(ClientProtocol namenode,

String src, <span class="keyword">long</span> start, <span class="keyword">long</span> length)</span> <span class="keyword">throws</span> IOException </span>{

<span class="function"><span class="keyword">return</span> namenode.<span class="title">getBlockLocations</span><span class="params">(src, start, length)</span></span>;

}
</code></pre><p>LocatedBlocks主要包含一个链表的List<locatedblock> blocks，其中每个LocatedBlock包含如下信息：</locatedblock></p>
<p>Block b：此block的信息<br>long offset：此block在文件中的偏移量<br>DatanodeInfo[] locs：此block位于哪些DataNode上<br>上面namenode.getBlockLocations是一个RPC调用，最终调用NameNode类的getBlockLocations函数。</p>
<p>1.2、NameNode<br>NameNode.getBlockLocations实现如下：</p>
<p>public LocatedBlocks   getBlockLocations(String src,</p>
<pre><code><span class="keyword">long</span> <span class="built_in">offset</span>,

<span class="keyword">long</span> <span class="built_in">length</span>) throws IOException {
</code></pre><p>  return namesystem.getBlockLocations(getClientMachine(),</p>
<pre><code>src, <span class="command">offset</span>, <span class="property">length</span>);
</code></pre><p>}</p>
<p>namesystem是NameNode一个成员变量，其类型为FSNamesystem，保存的是NameNode的name space树，其中一个重要的成员变量为FSDirectory dir。</p>
<p>FSDirectory和Lucene中的FSDirectory没有任何关系，其主要包括FSImage fsImage，用于读写硬盘上的fsimage文件，FSImage类有成员变量FSEditLog editLog，用于读写硬盘上的edit文件，这两个文件的关系在上一篇文章中已经解释过。</p>
<p>FSDirectory还有一个重要的成员变量INodeDirectoryWithQuota rootDir，INodeDirectoryWithQuota的父类为INodeDirectory，实现如下：</p>
<p>public class INodeDirectory extends INode {</p>
<p>  ……</p>
<p>  private List<inode> children;</inode></p>
<p>  ……</p>
<p>｝</p>
<p>由此可见INodeDirectory本身是一个INode，其中包含一个链表的INode，此链表中，如果仍为文件夹，则是类型INodeDirectory，如果是文件，则是类型INodeFile，INodeFile中有成员变量BlockInfo blocks[]，是此文件包含的block的信息。显然这是一棵树形的结构。</p>
<p>FSNamesystem.getBlockLocations函数如下：</p>
<p>public LocatedBlocks getBlockLocations(String src, long offset, long length,</p>
<pre><code><span class="keyword">boolean</span> doAccessTime) <span class="keyword">throws</span> IOException {
</code></pre><p>  final LocatedBlocks ret = getBlockLocationsInternal(src, dir.getFileINode(src),</p>
<pre><code><span class="command">offset</span>, <span class="property">length</span>, Integer.MAX_VALUE, doAccessTime); 
</code></pre><p>  return ret;</p>
<p>}</p>
<p>dir.getFileINode(src)通过路径名从文件系统树中找到INodeFile，其中保存的是要打开的文件的INode的信息。</p>
<p>getBlockLocationsInternal的实现如下：</p>
<p>private synchronized LocatedBlocks getBlockLocationsInternal(String src,</p>
<pre><code>INodeFile inode,

<span class="keyword">long</span> offset,

<span class="keyword">long</span> length,

<span class="keyword">int</span> nrBlocksToReturn,

<span class="keyword">boolean</span> doAccessTime)

<span class="keyword">throws</span> IOException {
</code></pre><p>  //得到此文件的block信息</p>
<p>  Block[] blocks = inode.getBlocks();</p>
<p>  List<locatedblock> results = new ArrayList<locatedblock>(blocks.length);</locatedblock></locatedblock></p>
<p>  //计算从offset开始，长度为length所涉及的blocks</p>
<p>  int curBlk = 0;</p>
<p>  long curPos = 0, blkSize = 0;</p>
<p>  int nrBlocks = (blocks[0].getNumBytes() == 0) ? 0 : blocks.length;</p>
<p>  for (curBlk = 0; curBlk &lt; nrBlocks; curBlk++) {</p>
<pre><code><span class="keyword">blkSize </span>= <span class="keyword">blocks[curBlk].getNumBytes();
</span>
<span class="label">if</span> (curPos + <span class="keyword">blkSize </span>&gt; offset) {

  //当offset在curPos和curPos + <span class="keyword">blkSize之间的时候，curBlk指向offset所在的block
</span>
  <span class="keyword">break;
</span>
}

<span class="label">curPos</span> += <span class="keyword">blkSize;</span>
</code></pre><p>  }</p>
<p>  long endOff = offset + length;</p>
<p>  //循环，依次遍历从curBlk开始的每个block，直到当前位置curPos越过endOff</p>
<p>  do {</p>
<pre><code><span class="label">int</span> numNodes = <span class="keyword">blocksMap.numNodes(blocks[curBlk]);
</span>
<span class="label">int</span> numCorruptNodes = countNodes(<span class="keyword">blocks[curBlk]).corruptReplicas();
</span>
<span class="label">int</span> numCorruptReplicas = corruptReplicas.numCorruptReplicas(<span class="keyword">blocks[curBlk]);
</span>
<span class="keyword">boolean </span><span class="keyword">blockCorrupt </span>= (numCorruptNodes == numNodes)<span class="comment">;</span>

<span class="label">int</span> numMachineSet = <span class="keyword">blockCorrupt </span>? numNodes :

                      (numNodes - numCorruptNodes)<span class="comment">;</span>

//依次找到此<span class="keyword">block所对应的datanode，将其中没有损坏的放入machineSet中
</span>
<span class="label">DatanodeDescriptor</span>[] machineSet = new DatanodeDescriptor[numMachineSet]<span class="comment">;</span>

<span class="label">if</span> (numMachineSet &gt; <span class="number">0</span>) {

  numNodes = <span class="number">0</span><span class="comment">;</span>

  for(<span class="keyword">Iterator&lt;DatanodeDescriptor&gt; </span><span class="keyword">it </span>=

      <span class="keyword">blocksMap.nodeIterator(blocks[curBlk]); </span><span class="keyword">it.hasNext();) </span>{

    DatanodeDescriptor <span class="preprocessor">dn</span> = <span class="keyword">it.next();
</span>
    <span class="keyword">boolean </span>replicaCorrupt = corruptReplicas.isReplicaCorrupt(<span class="keyword">blocks[curBlk], </span><span class="preprocessor">dn</span>)<span class="comment">;</span>

    <span class="preprocessor">if</span> (<span class="keyword">blockCorrupt </span><span class="title">||</span> (!<span class="keyword">blockCorrupt </span>&amp;&amp; !replicaCorrupt))

      machineSet[numNodes++] = <span class="preprocessor">dn</span><span class="comment">;</span>

  }

}

//使用此machineSet和当前的<span class="keyword">block构造一个LocatedBlock
</span>
<span class="label">results.add</span>(new LocatedBlock(<span class="keyword">blocks[curBlk], </span>machineSet, curPos,

            <span class="keyword">blockCorrupt));
</span>
<span class="label">curPos</span> += <span class="keyword">blocks[curBlk].getNumBytes();
</span>
<span class="label">curBlk</span>++<span class="comment">;</span>
</code></pre><p>  } while (curPos &lt; endOff</p>
<pre><code>&amp;&amp; <span class="tag">curBlk</span> &lt; <span class="tag">blocks</span><span class="class">.length</span>

&amp;&amp; <span class="tag">results</span><span class="class">.size</span>() &lt; <span class="tag">nrBlocksToReturn</span>);
</code></pre><p>  //使用此LocatedBlock链表构造一个LocatedBlocks对象返回</p>
<p>  return inode.createLocatedBlocks(results);</p>
<p>}</p>
<p>1.3、客户端<br>通过RPC调用，在NameNode得到的LocatedBlocks对象，作为成员变量构造DFSInputStream对象，最后包装为FSDataInputStream返回给用户。</p>
<p>二、文件的读取<br>2.1、客户端<br>文件读取的时候，客户端利用文件打开的时候得到的FSDataInputStream.read(long position, byte[] buffer, int offset, int length)函数进行文件读操作。</p>
<p>FSDataInputStream会调用其封装的DFSInputStream的read(long position, byte[] buffer, int offset, int length)函数，实现如下：</p>
<p>public int read(long position, byte[] buffer, int offset, int length)</p>
<p>  throws IOException {</p>
<p>  long filelen = getFileLength();</p>
<p>  int realLen = length;</p>
<p>  if ((position + length) &gt; filelen) {</p>
<pre><code>realLen = <span class="list">(<span class="keyword">int</span>)</span><span class="list">(<span class="keyword">filelen</span> - position)</span><span class="comment">;</span>
</code></pre><p>  }</p>
<p>  //首先得到包含从offset到offset + length内容的block列表</p>
<p>  //比如对于64M一个block的文件系统来说，欲读取从100M开始，长度为128M的数据，则block列表包括第2，3，4块block</p>
<p>  List<locatedblock> blockRange = getBlockRange(position, realLen);</locatedblock></p>
<p>  int remaining = realLen;</p>
<p>  //对每一个block，从中读取内容</p>
<p>  //对于上面的例子，对于第2块block，读取从36M开始，读取长度28M，对于第3块，读取整一块64M，对于第4块，读取从0开始，长度为36M，共128M数据</p>
<p>  for (LocatedBlock blk : blockRange) {</p>
<pre><code><span class="label">long</span> targetStart = position - <span class="keyword">blk.getStartOffset();
</span>
<span class="label">long</span> <span class="keyword">bytesToRead </span>= Math.min(remaining, <span class="keyword">blk.getBlockSize() </span>- targetStart)<span class="comment">;</span>

<span class="label">fetchBlockByteRange</span>(<span class="keyword">blk, </span>targetStart,

                    targetStart + <span class="keyword">bytesToRead </span>- <span class="number">1</span>, <span class="keyword">buffer, </span>offset)<span class="comment">;</span>

<span class="label">remaining</span> -= <span class="keyword">bytesToRead;
</span>
<span class="label">position</span> += <span class="keyword">bytesToRead;
</span>
<span class="label">offset</span> += <span class="keyword">bytesToRead;</span>
</code></pre><p>  }</p>
<p>  assert remaining == 0 : “Wrong number of bytes read.”;</p>
<p>  if (stats != null) {</p>
<pre><code><span class="tag">stats</span><span class="class">.incrementBytesRead</span>(<span class="tag">realLen</span>);
</code></pre><p>  }</p>
<p>  return realLen;</p>
<p>}</p>
<p>其中getBlockRange函数如下：</p>
<p>private synchronized List<locatedblock> getBlockRange(long offset,</locatedblock></p>
<pre><code>  <span class="keyword">long</span> length)

<span class="keyword">throws</span> IOException {
</code></pre><p>  List<locatedblock> blockRange = new ArrayList<locatedblock>();</locatedblock></locatedblock></p>
<p>  //首先从缓存的locatedBlocks中查找offset所在的block在缓存链表中的位置</p>
<p>  int blockIdx = locatedBlocks.findBlock(offset);</p>
<p>  if (blockIdx &lt; 0) { // block is not cached</p>
<pre><code><span class="built_in">block</span>Idx = LocatedBlocks.getInsertIndex(<span class="built_in">block</span>Idx);
</code></pre><p>  }</p>
<p>  long remaining = length;</p>
<p>  long curOff = offset;</p>
<p>  while(remaining &gt; 0) {</p>
<pre><code><span class="label">LocatedBlock</span> <span class="keyword">blk </span>= null<span class="comment">;</span>

//按照<span class="keyword">blockIdx的位置找到block
</span>
<span class="label">if</span>(<span class="keyword">blockIdx </span>&lt; locatedBlocks.locatedBlockCount())

  <span class="keyword">blk </span>= locatedBlocks.get(<span class="keyword">blockIdx);
</span>
//如果<span class="keyword">block为空，则缓存中没有此block，则直接从NameNode中查找这些block，并加入缓存
</span>
<span class="label">if</span> (<span class="keyword">blk </span>== null <span class="title">||</span> curOff &lt; <span class="keyword">blk.getStartOffset()) </span>{

  LocatedBlocks newBlocks<span class="comment">;</span>

  newBlocks = callGetBlockLocations(namenode, src, curOff, remaining)<span class="comment">;</span>

  locatedBlocks.insertRange(<span class="keyword">blockIdx, </span>newBlocks.getLocatedBlocks())<span class="comment">;</span>

  continue<span class="comment">;</span>

}

//如果<span class="keyword">block找到，则放入结果集
</span>
<span class="keyword">blockRange.add(blk);
</span>
<span class="label">long</span> <span class="keyword">bytesRead </span>= <span class="keyword">blk.getStartOffset() </span>+ <span class="keyword">blk.getBlockSize() </span>- curOff<span class="comment">;</span>

<span class="label">remaining</span> -= <span class="keyword">bytesRead;
</span>
<span class="label">curOff</span> += <span class="keyword">bytesRead;
</span>
//取下一个<span class="keyword">block
</span>
<span class="keyword">blockIdx++;</span>
</code></pre><p>  }</p>
<p>  return blockRange;</p>
<p>}</p>
<p>其中fetchBlockByteRange实现如下：</p>
<p>private void fetchBlockByteRange(LocatedBlock block, long start,</p>
<pre><code><span class="keyword">long</span> end, <span class="keyword">byte</span>[] buf, <span class="keyword">int</span> offset) <span class="keyword">throws</span> IOException {
</code></pre><p>  Socket dn = null;</p>
<p>  int numAttempts = block.getLocations().length;</p>
<p>  //此while循环为读取失败后的重试次数</p>
<p>  while (dn == null &amp;&amp; numAttempts– &gt; 0 ) {</p>
<pre><code>//选择一个DataNode来读取数据

DNAddrPair retval = chooseDataNode(block)<span class="comment">;</span>

DatanodeInfo chosenNode = retval.info<span class="comment">;</span>

InetSocketAddress targetAddr = retval.addr<span class="comment">;</span>

BlockReader reader = null<span class="comment">;</span>

try {

  //创建Socket连接到DataNode

  dn = socketFactory.createSocket()<span class="comment">;</span>

  dn.connect(targetAddr, socketTimeout)<span class="comment">;</span>

  dn.setSoTimeout(socketTimeout)<span class="comment">;</span>

  int len = (int) (end - start + 1)<span class="comment">;</span>

  //利用建立的Socket链接，生成一个reader负责从DataNode读取数据

  reader = BlockReader.newBlockReader(dn, src,

                                      block.getBlock().getBlockId(),

                                      block.getBlock().getGenerationStamp(),

                                      start, len, buffersize,

                                      verifyChecksum, clientName)<span class="comment">;</span>

  //读取数据

  int nread = reader.readAll(buf, offset, len)<span class="comment">;</span>

  return<span class="comment">;</span>

} finally {

  IOUtils.closeStream(reader)<span class="comment">;</span>

  IOUtils.closeSocket(dn)<span class="comment">;</span>

  dn = null<span class="comment">;</span>

}

//如果读取失败，则将此DataNode标记为失败节点

addToDeadNodes(chosenNode)<span class="comment">;</span>
</code></pre><p>  }</p>
<p>}</p>
<p>BlockReader.newBlockReader函数实现如下：</p>
<p>public static BlockReader newBlockReader( Socket sock, String file,</p>
<pre><code><span class="keyword">long</span> blockId,

<span class="keyword">long</span> genStamp,

<span class="keyword">long</span> startOffset, <span class="keyword">long</span> len,

<span class="built_in">int</span> bufferSize, <span class="built_in">boolean</span> verifyChecksum,

<span class="keyword">String</span> clientName)

<span class="keyword">throws</span> IOException {
</code></pre><p>  //使用Socket建立写入流，向DataNode发送读指令</p>
<p>  DataOutputStream out = new DataOutputStream(</p>
<pre><code><span class="tag">new</span> <span class="tag">BufferedOutputStream</span>(<span class="tag">NetUtils</span><span class="class">.getOutputStream</span>(<span class="tag">sock</span>,<span class="tag">HdfsConstants</span><span class="class">.WRITE_TIMEOUT</span>)));
</code></pre><p>  out.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );</p>
<p>  out.write( DataTransferProtocol.OP_READ_BLOCK );</p>
<p>  out.writeLong( blockId );</p>
<p>  out.writeLong( genStamp );</p>
<p>  out.writeLong( startOffset );</p>
<p>  out.writeLong( len );</p>
<p>  Text.writeString(out, clientName);</p>
<p>  out.flush();</p>
<p>  //使用Socket建立读入流，用于从DataNode读取数据</p>
<p>  DataInputStream in = new DataInputStream(</p>
<pre><code><span class="keyword">new</span> BufferedInputStream(NetUtils.getInputStream(sock),

                        bufferSize));
</code></pre><p>  DataChecksum checksum = DataChecksum.newDataChecksum( in );</p>
<p>  long firstChunkOffset = in.readLong();</p>
<p>  //生成一个reader，主要包含读入流，用于读取数据</p>
<p>  return new BlockReader( file, blockId, in, checksum, verifyChecksum,</p>
<pre><code>startOffset, firstChunkOffset, sock )<span class="comment">;</span>
</code></pre><p>}</p>
<p>BlockReader的readAll函数就是用上面生成的DataInputStream读取数据。</p>
<p>2.2、DataNode<br>在DataNode启动的时候，会调用函数startDataNode，其中与数据读取有关的逻辑如下：</p>
<p>void startDataNode(Configuration conf,</p>
<pre><code>AbstractList&lt;<span class="keyword">File</span>&gt; dataDirs

) <span class="keyword">throws</span> IOException {
</code></pre><p>  ……</p>
<p>  // 建立一个ServerSocket，并生成一个DataXceiverServer来监控客户端的链接</p>
<p>  ServerSocket ss = (socketWriteTimeout &gt; 0) ?</p>
<pre><code><span class="type">ServerSocketChannel</span>.<span class="keyword">open</span><span class="literal">()</span>.socket<span class="literal">()</span> : new <span class="type">ServerSocket</span><span class="literal">()</span>;
</code></pre><p>  Server.bind(ss, socAddr, 0);</p>
<p>  ss.setReceiveBufferSize(DEFAULT_DATA_SOCKET_SIZE);</p>
<p>  // adjust machine name with the actual port</p>
<p>  tmpPort = ss.getLocalPort();</p>
<p>  selfAddr = new InetSocketAddress(ss.getInetAddress().getHostAddress(),</p>
<pre><code>tmpPort)<span class="comment">;</span>
</code></pre><p>  this.dnRegistration.setName(machineName + “:” + tmpPort);</p>
<p>  this.threadGroup = new ThreadGroup(“dataXceiverServer”);</p>
<p>  this.dataXceiverServer = new Daemon(threadGroup,</p>
<pre><code><span class="keyword">new</span> DataXceiverServer(ss, conf, <span class="keyword">this</span>));
</code></pre><p>  this.threadGroup.setDaemon(true); // auto destroy when empty</p>
<p>  ……</p>
<p>}</p>
<p>DataXceiverServer.run()函数如下：</p>
<p>public void run() {</p>
<p>  while (datanode.shouldRun) {</p>
<pre><code><span class="comment">//接受客户端的链接</span>

Socket s = ss.accept();

s.setTcpNoDelay(<span class="literal">true</span>);

<span class="comment">//生成一个线程DataXceiver来对建立的链接提供服务</span>

<span class="keyword">new</span> Daemon(datanode.threadGroup,

    <span class="keyword">new</span> DataXceiver(s, datanode, <span class="keyword">this</span>)).start();
</code></pre><p>  }</p>
<p>  try {</p>
<pre><code><span class="tag">ss</span><span class="class">.close</span>();
</code></pre><p>  } catch (IOException ie) {</p>
<pre><code><span class="tag">LOG</span><span class="class">.warn</span>(<span class="tag">datanode</span><span class="class">.dnRegistration</span> + "<span class="pseudo">:DataXceiveServer</span>: "

                        + <span class="tag">StringUtils</span><span class="class">.stringifyException</span>(<span class="tag">ie</span>));
</code></pre><p>  }</p>
<p>}</p>
<p>DataXceiver.run()函数如下：</p>
<p>public void run() {</p>
<p>  DataInputStream in=null;</p>
<p>  try {</p>
<pre><code><span class="comment">//建立一个输入流，读取客户端发送的指令</span>

<span class="keyword">in</span> = <span class="keyword">new</span> DataInputStream(

    <span class="keyword">new</span> BufferedInputStream(NetUtils.getInputStream(s),

                            SMALL_BUFFER_SIZE));

<span class="typename">short</span> version = <span class="keyword">in</span>.readShort();

<span class="typename">boolean</span> local = s.getInetAddress().equals(s.getLocalAddress());

<span class="typename">byte</span> op = <span class="keyword">in</span>.readByte();

<span class="comment">// Make sure the xciver count is not exceeded</span>

<span class="typename">int</span> curXceiverCount = datanode.getXceiverCount();

<span class="typename">long</span> startTime = DataNode.now();

<span class="keyword">switch</span> ( op ) {

<span class="comment">//读取</span>

<span class="keyword">case</span> DataTransferProtocol.<span class="string">OP_READ_BLOCK:</span>

  <span class="comment">//真正的读取数据</span>

  readBlock( <span class="keyword">in</span> );

  datanode.myMetrics.readBlockOp.inc(DataNode.now() - startTime);

  <span class="keyword">if</span> (local)

    datanode.myMetrics.readsFromLocalClient.inc();

  <span class="keyword">else</span>

    datanode.myMetrics.readsFromRemoteClient.inc();

  <span class="keyword">break</span>;

<span class="comment">//写入</span>

<span class="keyword">case</span> DataTransferProtocol.<span class="string">OP_WRITE_BLOCK:</span>

  <span class="comment">//真正的写入数据</span>

  writeBlock( <span class="keyword">in</span> );

  datanode.myMetrics.writeBlockOp.inc(DataNode.now() - startTime);

  <span class="keyword">if</span> (local)

    datanode.myMetrics.writesFromLocalClient.inc();

  <span class="keyword">else</span>

    datanode.myMetrics.writesFromRemoteClient.inc();

  <span class="keyword">break</span>;

<span class="comment">//其他的指令</span>

……

}
</code></pre><p>  } catch (Throwable t) {</p>
<pre><code><span class="tag">LOG</span><span class="class">.error</span>(<span class="tag">datanode</span><span class="class">.dnRegistration</span> + "<span class="pseudo">:DataXceiver"</span>,<span class="tag">t</span>);
</code></pre><p>  } finally {</p>
<pre><code><span class="tag">IOUtils</span><span class="class">.closeStream</span>(<span class="tag">in</span>);

<span class="tag">IOUtils</span><span class="class">.closeSocket</span>(<span class="tag">s</span>);

<span class="tag">dataXceiverServer</span><span class="class">.childSockets</span><span class="class">.remove</span>(<span class="tag">s</span>);
</code></pre><p>  }</p>
<p>}</p>
<p>private void readBlock(DataInputStream in) throws IOException {</p>
<p>  //读取指令</p>
<p>  long blockId = in.readLong();         </p>
<p>  Block block = new Block( blockId, 0 , in.readLong());</p>
<p>  long startOffset = in.readLong();</p>
<p>  long length = in.readLong();</p>
<p>  String clientName = Text.readString(in);</p>
<p>  //创建一个写入流，用于向客户端写数据</p>
<p>  OutputStream baseStream = NetUtils.getOutputStream(s,</p>
<pre><code><span class="tag">datanode</span><span class="class">.socketWriteTimeout</span>);
</code></pre><p>  DataOutputStream out = new DataOutputStream(</p>
<pre><code><span class="keyword">new</span> BufferedOutputStream(baseStream, SMALL_BUFFER_SIZE));
</code></pre><p>  //生成BlockSender用于读取本地的block的数据，并发送给客户端</p>
<p>  //BlockSender有一个成员变量InputStream blockIn用于读取本地block的数据</p>
<p>  BlockSender blockSender = new BlockSender(block, startOffset, length,</p>
<pre><code><span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, datanode, clientTraceFmt);
</code></pre><p>   out.writeShort(DataTransferProtocol.OP_STATUS_SUCCESS); // send op status</p>
<p>   //向客户端写入数据</p>
<p>   long read = blockSender.sendBlock(out, baseStream, null);</p>
<p>   ……</p>
<p>  } finally {</p>
<pre><code><span class="tag">IOUtils</span><span class="class">.closeStream</span>(<span class="tag">out</span>);

<span class="tag">IOUtils</span><span class="class">.closeStream</span>(<span class="tag">blockSender</span>);
</code></pre><p>  }</p>
<p>}</p>
<p>三、文件的写入<br>下面解析向hdfs上传一个文件的过程。</p>
<p>3.1、客户端<br>上传一个文件到hdfs，一般会调用DistributedFileSystem.create，其实现如下：</p>
<p>  public FSDataOutputStream create(Path f, FsPermission permission,</p>
<pre><code><span class="keyword">boolean</span> overwrite,

<span class="keyword">int</span> bufferSize, <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize,

Progressable progress) <span class="keyword">throws</span> IOException {

<span class="keyword">return</span> <span class="keyword">new</span> FSDataOutputStream

   (dfs.create(getPathName(f), permission,

               overwrite, replication, blockSize, progress, bufferSize),

    statistics);
</code></pre><p>  }</p>
<p>其最终生成一个FSDataOutputStream用于向新生成的文件中写入数据。其成员变量dfs的类型为DFSClient，DFSClient的create函数如下：</p>
<p>  public OutputStream create(String src,</p>
<pre><code>                         <span class="type">FsPermission</span> permission,

                         boolean overwrite,

                         short replication,

                         long blockSize,

                         <span class="type">Progressable</span> progress,

                         <span class="type">int</span> buffersize

                         ) throws <span class="type">IOException</span> {

checkOpen();

<span class="keyword">if</span> (permission == null) {

  permission = <span class="type">FsPermission</span>.getDefault();

}

<span class="type">FsPermission</span> masked = permission.applyUMask(<span class="type">FsPermission</span>.getUMask(conf));

<span class="type">OutputStream</span> <span class="literal">result</span> = new <span class="type">DFSOutputStream</span>(src, masked,

    overwrite, replication, blockSize, progress, buffersize,

    conf.getInt(<span class="string">"io.bytes.per.checksum"</span>, <span class="number">512</span>));

leasechecker.put(src, <span class="literal">result</span>);

<span class="keyword">return</span> <span class="literal">result</span>;
</code></pre><p>  }</p>
<p>其中构造了一个DFSOutputStream，在其构造函数中，同过RPC调用NameNode的create来创建一个文件。<br>当然，构造函数中还做了一件重要的事情，就是streamer.start()，也即启动了一个pipeline，用于写数据，在写入数据的过程中，我们会仔细分析。</p>
<p>  DFSOutputStream(String src, FsPermission masked, boolean overwrite,</p>
<pre><code>  <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, Progressable progress,

  <span class="keyword">int</span> buffersize, <span class="keyword">int</span> bytesPerChecksum) <span class="keyword">throws</span> IOException {

<span class="keyword">this</span>(src, blockSize, progress, bytesPerChecksum);

computePacketChunkSize(writePacketSize, bytesPerChecksum);

<span class="keyword">try</span> {

  namenode.create(

      src, masked, clientName, overwrite, replication, blockSize);

} <span class="keyword">catch</span>(RemoteException re) {

  <span class="keyword">throw</span> re.unwrapRemoteException(AccessControlException.<span class="keyword">class</span>,

                                 QuotaExceededException.<span class="keyword">class</span>);

}

streamer.start();
</code></pre><p>  }</p>
<p>3.2、NameNode<br>NameNode的create函数调用namesystem.startFile函数，其又调用startFileInternal函数，实现如下：</p>
<p>  private synchronized void startFileInternal(String src,</p>
<pre><code>                                          PermissionStatus permissions,

                                          <span class="keyword">String</span> holder,

                                          <span class="keyword">String</span> clientMachine,

                                          <span class="built_in">boolean</span> overwrite,

                                          <span class="built_in">boolean</span> <span class="built_in">append</span>,

                                          <span class="keyword">short</span> replication,

                                          <span class="keyword">long</span> blockSize

                                          ) <span class="keyword">throws</span> IOException {

......
</code></pre><p>   //创建一个新的文件，状态为under construction，没有任何data block与之对应</p>
<p>   long genstamp = nextGenerationStamp();</p>
<p>   INodeFileUnderConstruction newNode = dir.addFile(src, permissions,</p>
<pre><code><span class="label">replication</span>, <span class="keyword">blockSize, </span>holder, clientMachine, clientNode, genstamp)<span class="comment">;</span>
</code></pre><p>   ……</p>
<p>  }</p>
<p>3.3、客户端<br>下面轮到客户端向新创建的文件中写入数据了，一般会使用FSDataOutputStream的write函数，最终会调用DFSOutputStream的writeChunk函数：</p>
<p>按照hdfs的设计，对block的数据写入使用的是pipeline的方式，也即将数据分成一个个的package，如果需要复制三分，分别写入DataNode 1, 2, 3，则会进行如下的过程：</p>
<p>首先将package 1写入DataNode 1<br>然后由DataNode 1负责将package 1写入DataNode 2，同时客户端可以将pacage 2写入DataNode 1<br>然后DataNode 2负责将package 1写入DataNode 3, 同时客户端可以讲package 3写入DataNode 1，DataNode 1将package 2写入DataNode 2<br>就这样将一个个package排着队的传递下去，直到所有的数据全部写入并复制完毕<br>  protected synchronized void writeChunk(byte[] b, int offset, int len, byte[] checksum)</p>
<pre><code>                                                  throws IOException {

<span class="comment">//创建一个package，并写入数据</span>

currentPacket = <span class="literal">new</span> Packet(packetSize, chunksPerPacket,

                             bytesCurBlock);

currentPacket<span class="built_in">.</span>writeChecksum(checksum, <span class="number">0</span>, cklen);

currentPacket<span class="built_in">.</span>writeData(b, offset, len);

currentPacket<span class="built_in">.</span>numChunks++;

bytesCurBlock += len;

<span class="comment">//如果此package已满，则放入队列中准备发送</span>

<span class="keyword">if</span> (currentPacket<span class="built_in">.</span>numChunks == currentPacket<span class="built_in">.</span>maxChunks <span class="subst">||</span>

    bytesCurBlock == blockSize) {

    <span class="attribute">...</span><span class="attribute">...</span>

    dataQueue<span class="built_in">.</span>addLast(currentPacket);

    <span class="comment">//唤醒等待dataqueue的传输线程，也即DataStreamer</span>

    dataQueue<span class="built_in">.</span>notifyAll();

    currentPacket = <span class="built_in">null</span>;

    <span class="attribute">...</span><span class="attribute">...</span>

}
</code></pre><p>  }</p>
<p>DataStreamer的run函数如下：</p>
<p>  public void run() {</p>
<pre><code><span class="keyword">while</span> (!closed &amp;&amp; clientRunning) {

  Packet one = <span class="keyword">null</span>;

  <span class="keyword">synchronized</span> (dataQueue) {

    <span class="comment">//如果队列中没有package，则等待</span>

    <span class="keyword">while</span> ((!closed &amp;&amp; !hasError &amp;&amp; clientRunning

           &amp;&amp; dataQueue.<span class="keyword">size</span>() == <span class="number">0</span>) || doSleep) {

      <span class="keyword">try</span> {

        dataQueue.wait(<span class="number">1000</span>);

      } <span class="keyword">catch</span> (InterruptedException  e) {

      }

      doSleep = <span class="keyword">false</span>;

    }

    <span class="keyword">try</span> {

      <span class="comment">//得到队列中的第一个package</span>

      one = dataQueue.getFirst();

      <span class="keyword">long</span> offsetInBlock = one.offsetInBlock;

      <span class="comment">//由NameNode分配block，并生成一个写入流指向此block</span>

      <span class="keyword">if</span> (blockStream == <span class="keyword">null</span>) {

        nodes = nextBlockOutputStream(src);

        response = <span class="keyword">new</span> ResponseProcessor(nodes);

        response.start();

      }

      ByteBuffer buf = one.getBuffer();

      <span class="comment">//将package从dataQueue移至ackQueue,等待确认</span>

      dataQueue.removeFirst();

      dataQueue.notifyAll();

      <span class="keyword">synchronized</span> (ackQueue) {

        ackQueue.addLast(one);

        ackQueue.notifyAll();

      }

      <span class="comment">//利用生成的写入流将数据写入DataNode中的block</span>

      blockStream.<span class="keyword">write</span>(buf.array(), buf.position(), buf.remaining());

      <span class="keyword">if</span> (one.lastPacketInBlock) {

        blockStream.writeInt(<span class="number">0</span>); <span class="comment">//表示此block写入完毕</span>

      }

      blockStream.flush();

    } <span class="keyword">catch</span> (Throwable e) {

    }

  }

  ......
</code></pre><p>  }</p>
<p>其中重要的一个函数是nextBlockOutputStream，实现如下：</p>
<p>  private DatanodeInfo[] nextBlockOutputStream(String client) throws IOException {</p>
<pre><code>LocatedBlock lb = <span class="keyword">null</span>;

<span class="keyword">boolean</span> retry = <span class="keyword">false</span>;

DatanodeInfo[] nodes;

<span class="keyword">int</span> <span class="keyword">count</span> = conf.getInt(<span class="string">"dfs.client.block.write.retries"</span>, <span class="number">3</span>);

<span class="keyword">boolean</span> success;

<span class="keyword">do</span> {

  ......

  <span class="comment">//由NameNode为文件分配DataNode和block</span>

  lb = locateFollowingBlock(startTime);

  block = lb.getBlock();

  nodes = lb.getLocations();

  <span class="comment">//创建向DataNode的写入流</span>

  success = createBlockOutputStream(nodes, clientName, <span class="keyword">false</span>);

  ......

} <span class="keyword">while</span> (retry &amp;&amp; --<span class="keyword">count</span> &gt;= <span class="number">0</span>);

<span class="keyword">return</span> nodes;
</code></pre><p>  }</p>
<p>locateFollowingBlock中通过RPC调用namenode.addBlock(src, clientName)函数</p>
<p>3.4、NameNode<br>NameNode的addBlock函数实现如下：</p>
<p>  public LocatedBlock addBlock(String src,</p>
<pre><code>                           <span class="title">String</span> clientName) throws IOException {

<span class="title">LocatedBlock</span> locatedBlock = namesystem.getAdditionalBlock(src, clientName);

<span class="title">return</span> locatedBlock;
</code></pre><p>  }</p>
<p>FSNamesystem的getAdditionalBlock实现如下：</p>
<p>  public LocatedBlock getAdditionalBlock(String src,</p>
<pre><code>                                     <span class="keyword">String</span> clientName

                                     ) <span class="keyword">throws</span> IOException {

<span class="keyword">long</span> fileLength, blockSize;

<span class="built_in">int</span> replication;

DatanodeDescriptor clientNode = <span class="keyword">null</span>;

Block newBlock = <span class="keyword">null</span>;

......

<span class="comment">//为新的block选择DataNode</span>

DatanodeDescriptor targets[] = replicator.chooseTarget(replication,

                                                       clientNode,

                                                       <span class="keyword">null</span>,

                                                       blockSize);

......

<span class="comment">//得到文件路径中所有path的INode，其中最后一个是新添加的文件对的INode，状态为under construction</span>

INode[] pathINodes = dir.getExistingPathINodes(src);

<span class="built_in">int</span> inodesLen = pathINodes.length;

INodeFileUnderConstruction pendingFile  = (INodeFileUnderConstruction)

                                            pathINodes[inodesLen - <span class="number">1</span>];

<span class="comment">//为文件分配block, 并设置在那写DataNode上</span>

newBlock = allocateBlock(src, pathINodes);

pendingFile.setTargets(targets);

......

<span class="keyword">return</span> <span class="keyword">new</span> LocatedBlock(newBlock, targets, fileLength);
</code></pre><p>  }</p>
<p>3.5、客户端<br>在分配了DataNode和block以后，createBlockOutputStream开始写入数据。</p>
<p>  private boolean createBlockOutputStream(DatanodeInfo[] nodes, String client,</p>
<pre><code>            boolean recoveryFlag) {

<span class="comment">//创建一个socket，链接DataNode</span>

InetSocketAddress target = NetUtils.createSocketAddr(nodes[<span class="number">0</span>].getName());

s = socketFactory.createSocket();

<span class="keyword">int</span> timeoutValue = <span class="number">3000</span> * nodes.length + socketTimeout;

s.connect(target, timeoutValue);

s.setSoTimeout(timeoutValue);

s.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);

<span class="keyword">long</span> writeTimeout = HdfsConstants.WRITE_TIMEOUT_EXTENSION * nodes.length +

                    datanodeWriteTimeout;

DataOutputStream <span class="keyword">out</span> = <span class="keyword">new</span> DataOutputStream(

    <span class="keyword">new</span> BufferedOutputStream(NetUtils.getOutputStream(s, writeTimeout),

                             DataNode.SMALL_BUFFER_SIZE));

blockReplyStream = <span class="keyword">new</span> DataInputStream(NetUtils.getInputStream(s));

<span class="comment">//写入指令</span>

<span class="keyword">out</span>.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

<span class="keyword">out</span>.write( DataTransferProtocol.OP_WRITE_BLOCK );

<span class="keyword">out</span>.writeLong( block.getBlockId() );

<span class="keyword">out</span>.writeLong( block.getGenerationStamp() );

<span class="keyword">out</span>.writeInt( nodes.length );

<span class="keyword">out</span>.writeBoolean( recoveryFlag );

Text.writeString( <span class="keyword">out</span>, client );

<span class="keyword">out</span>.writeBoolean(<span class="keyword">false</span>);

<span class="keyword">out</span>.writeInt( nodes.length - <span class="number">1</span> );

<span class="comment">//注意，次循环从1开始，而非从0开始。将除了第一个DataNode以外的另外两个DataNode的信息发送给第一个DataNode, 第一个DataNode可以根据此信息将数据写给另两个DataNode</span>

<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nodes.length; i++) {

  nodes[i].write(<span class="keyword">out</span>);

}

checksum.writeHeader( <span class="keyword">out</span> );

<span class="keyword">out</span>.flush();

firstBadLink = Text.readString(blockReplyStream);

<span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) {

  <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink "</span> + firstBadLink);

}

blockStream = <span class="keyword">out</span>;
</code></pre><p>  }</p>
<p>客户端在DataStreamer的run函数中创建了写入流后，调用blockStream.write将数据写入DataNode</p>
<p>3.6、DataNode<br>DataNode的DataXceiver中，收到指令DataTransferProtocol.OP_WRITE_BLOCK则调用writeBlock函数：</p>
<p>  private void writeBlock(DataInputStream in) throws IOException {</p>
<pre><code>DatanodeInfo srcDataNode = <span class="keyword">null</span>;

<span class="comment">//读入头信息</span>

Block block = <span class="keyword">new</span> Block(<span class="keyword">in</span>.readLong(),

    dataXceiverServer.estimateBlockSize, <span class="keyword">in</span>.readLong());

<span class="built_in">int</span> pipelineSize = <span class="keyword">in</span>.readInt(); <span class="comment">// num of datanodes in entire pipeline</span>

boolean isRecovery = <span class="keyword">in</span>.readBoolean(); <span class="comment">// is this part of recovery?</span>

<span class="built_in">String</span> client = Text.readString(<span class="keyword">in</span>); <span class="comment">// working on behalf of this client</span>

boolean hasSrcDataNode = <span class="keyword">in</span>.readBoolean(); <span class="comment">// is src node info present</span>

<span class="keyword">if</span> (hasSrcDataNode) {

  srcDataNode = <span class="keyword">new</span> DatanodeInfo();

  srcDataNode.readFields(<span class="keyword">in</span>);

}

<span class="built_in">int</span> numTargets = <span class="keyword">in</span>.readInt();

<span class="keyword">if</span> (numTargets &lt; <span class="number">0</span>) {

  <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Mislabelled incoming datastream."</span>);

}

<span class="comment">//读入剩下的DataNode列表，如果当前是第一个DataNode，则此列表中收到的是第二个，第三个DataNode的信息，如果当前是第二个DataNode，则受到的是第三个DataNode的信息</span>

DatanodeInfo targets[] = <span class="keyword">new</span> DatanodeInfo[numTargets];

<span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; targets.length; i++) {

  DatanodeInfo tmp = <span class="keyword">new</span> DatanodeInfo();

  tmp.readFields(<span class="keyword">in</span>);

  targets[i] = tmp;

}

DataOutputStream mirrorOut = <span class="keyword">null</span>;  <span class="comment">// stream to next target</span>

DataInputStream mirrorIn = <span class="keyword">null</span>;    <span class="comment">// reply from next target</span>

DataOutputStream replyOut = <span class="keyword">null</span>;   <span class="comment">// stream to prev target</span>

Socket mirrorSock = <span class="keyword">null</span>;           <span class="comment">// socket to next target</span>

BlockReceiver blockReceiver = <span class="keyword">null</span>; <span class="comment">// responsible for data handling</span>

<span class="built_in">String</span> mirrorNode = <span class="keyword">null</span>;           <span class="comment">// the name:port of next target</span>

<span class="built_in">String</span> firstBadLink = <span class="string">""</span>;           <span class="comment">// first datanode that failed in connection setup</span>

<span class="keyword">try</span> {

  <span class="comment">//生成一个BlockReceiver, 其有成员变量DataInputStream in为从客户端或者上一个DataNode读取数据，还有成员变量DataOutputStream mirrorOut，用于向下一个DataNode写入数据，还有成员变量OutputStream out用于将数据写入本地。</span>

  blockReceiver = <span class="keyword">new</span> BlockReceiver(block, <span class="keyword">in</span>,

      s.getRemoteSocketAddress().toString(),

      s.getLocalSocketAddress().toString(),

      isRecovery, client, srcDataNode, datanode);

  <span class="comment">// get a connection back to the previous target</span>

  replyOut = <span class="keyword">new</span> DataOutputStream(

                 NetUtils.getOutputStream(s, datanode.socketWriteTimeout));

  <span class="comment">//如果当前不是最后一个DataNode，则同下一个DataNode建立socket连接</span>

  <span class="keyword">if</span> (targets.length &gt; <span class="number">0</span>) {

    InetSocketAddress mirrorTarget = <span class="keyword">null</span>;

    <span class="comment">// Connect to backup machine</span>

    mirrorNode = targets[<span class="number">0</span>].getName();

    mirrorTarget = NetUtils.createSocketAddr(mirrorNode);

    mirrorSock = datanode.newSocket();

    <span class="built_in">int</span> timeoutValue = numTargets * datanode.socketTimeout;

    <span class="built_in">int</span> writeTimeout = datanode.socketWriteTimeout +

                         (HdfsConstants.WRITE_TIMEOUT_EXTENSION * numTargets);

    mirrorSock.connect(mirrorTarget, timeoutValue);

    mirrorSock.setSoTimeout(timeoutValue);

    mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);

    <span class="comment">//创建向下一个DataNode写入数据的流</span>

    mirrorOut = <span class="keyword">new</span> DataOutputStream(

         <span class="keyword">new</span> BufferedOutputStream(

                     NetUtils.getOutputStream(mirrorSock, writeTimeout),

                     SMALL_BUFFER_SIZE));

    mirrorIn = <span class="keyword">new</span> DataInputStream(NetUtils.getInputStream(mirrorSock));

    mirrorOut.writeShort( DataTransferProtocol.DATA_TRANSFER_VERSION );

    mirrorOut.write( DataTransferProtocol.OP_WRITE_BLOCK );

    mirrorOut.writeLong( block.getBlockId() );

    mirrorOut.writeLong( block.getGenerationStamp() );

    mirrorOut.writeInt( pipelineSize );

    mirrorOut.writeBoolean( isRecovery );

    Text.writeString( mirrorOut, client );

    mirrorOut.writeBoolean(hasSrcDataNode);

    <span class="keyword">if</span> (hasSrcDataNode) { <span class="comment">// pass src node information</span>

      srcDataNode.write(mirrorOut);

    }

    mirrorOut.writeInt( targets.length - <span class="number">1</span> );

    <span class="comment">//此出也是从1开始，将除了下一个DataNode的其他DataNode信息发送给下一个DataNode</span>

    <span class="keyword">for</span> ( <span class="built_in">int</span> i = <span class="number">1</span>; i &lt; targets.length; i++ ) {

      targets[i].write( mirrorOut );

    }

    blockReceiver.writeChecksumHeader(mirrorOut);

    mirrorOut.flush();

  }

  <span class="comment">//使用BlockReceiver接受block</span>

  <span class="built_in">String</span> mirrorAddr = (mirrorSock == <span class="keyword">null</span>) ? <span class="keyword">null</span> : mirrorNode;

  blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,

                             mirrorAddr, <span class="keyword">null</span>, targets.length);

  ......

} <span class="keyword">finally</span> {

  <span class="comment">// close all opened streams</span>

  IOUtils.closeStream(mirrorOut);

  IOUtils.closeStream(mirrorIn);

  IOUtils.closeStream(replyOut);

  IOUtils.closeSocket(mirrorSock);

  IOUtils.closeStream(blockReceiver);

}
</code></pre><p>  }</p>
<p>BlockReceiver的receiveBlock函数中，一段重要的逻辑如下：</p>
<p>  void receiveBlock(</p>
<pre><code>DataOutputStream mirrOut, <span class="comment">// output to next datanode</span>

DataInputStream mirrIn,   <span class="comment">// input from next datanode</span>

DataOutputStream replyOut,  <span class="comment">// output to previous datanode</span>

<span class="built_in">String</span> mirrAddr, BlockTransferThrottler throttlerArg,

int numTargets) throws IOException {

<span class="attribute">...</span><span class="attribute">...</span>

<span class="comment">//不断的接受package，直到结束</span>

<span class="keyword">while</span> (receivePacket() &gt; <span class="number">0</span>) {}

<span class="keyword">if</span> (mirrorOut != <span class="built_in">null</span>) {

  try {

    mirrorOut<span class="built_in">.</span>writeInt(<span class="number">0</span>); <span class="comment">// mark the end of the block</span>

    mirrorOut<span class="built_in">.</span>flush();

  } catch (IOException e) {

    handleMirrorOutErr<span class="subst">or</span>(e);

  }

}

<span class="attribute">...</span><span class="attribute">...</span>
</code></pre><p>  }</p>
<p>BlockReceiver的receivePacket函数如下：</p>
<p>  private int receivePacket() throws IOException {</p>
<pre><code><span class="comment">//从客户端或者上一个节点接收一个package</span>

int payloadLen <span class="keyword">=</span> readNextPacket();

<span class="keyword">buf</span><span class="typename">.mark</span>();

<span class="comment">//read the header</span>

<span class="keyword">buf</span><span class="typename">.getInt</span>(); <span class="comment">// packet length</span>

offsetInBlock <span class="keyword">=</span> <span class="keyword">buf</span><span class="typename">.getLong</span>(); <span class="comment">// get offset of packet in block</span>

long seqno <span class="keyword">=</span> <span class="keyword">buf</span><span class="typename">.getLong</span>();    <span class="comment">// get seqno</span>

boolean lastPacketInBlock <span class="keyword">=</span> (<span class="keyword">buf</span><span class="typename">.get</span>() <span class="keyword">!</span><span class="keyword">=</span> <span class="number">0</span>);

int endOfHeader <span class="keyword">=</span> <span class="keyword">buf</span><span class="typename">.position</span>();

<span class="keyword">buf</span><span class="typename">.reset</span>();

setBlockPosition(offsetInBlock);

<span class="comment">//将package写入下一个DataNode</span>

<span class="keyword">if</span> (mirrorOut <span class="keyword">!</span><span class="keyword">=</span> null) <span class="keyword">{</span>

  try <span class="keyword">{</span>

    mirrorOut<span class="typename">.write</span>(<span class="keyword">buf</span><span class="typename">.array</span>(), <span class="keyword">buf</span><span class="typename">.position</span>(), <span class="keyword">buf</span><span class="typename">.remaining</span>());

    mirrorOut<span class="typename">.flush</span>();

  <span class="keyword">}</span> catch (IOException e) <span class="keyword">{</span>

    handleMirrorOutError(e);

  <span class="keyword">}</span>

<span class="keyword">}</span>

<span class="keyword">buf</span><span class="typename">.position</span>(endOfHeader);       

int len <span class="keyword">=</span> <span class="keyword">buf</span><span class="typename">.getInt</span>();

offsetInBlock <span class="keyword">+</span><span class="keyword">=</span> len;

int checksumLen <span class="keyword">=</span> ((len <span class="keyword">+</span> bytesPerChecksum <span class="keyword">-</span> <span class="number">1</span>)<span class="keyword">/</span>bytesPerChecksum)<span class="keyword">*</span>

                                                        checksumSize;

int checksumOff <span class="keyword">=</span> <span class="keyword">buf</span><span class="typename">.position</span>();

int dataOff <span class="keyword">=</span> checksumOff <span class="keyword">+</span> checksumLen;

byte pktBuf[] <span class="keyword">=</span> <span class="keyword">buf</span><span class="typename">.array</span>();

<span class="keyword">buf</span><span class="typename">.position</span>(<span class="keyword">buf</span><span class="typename">.limit</span>()); <span class="comment">// move to the end of the data.</span>

......

<span class="comment">//将数据写入本地的block</span>

out<span class="typename">.write</span>(pktBuf, dataOff, len);

<span class="comment">/// flush entire packet before sending ack</span>

flush();

<span class="comment">// put in queue for pending acks</span>

<span class="keyword">if</span> (responder <span class="keyword">!</span><span class="keyword">=</span> null) <span class="keyword">{</span>

  ((PacketResponder)responder<span class="typename">.getRunnable</span>())<span class="typename">.enqueue</span>(seqno,

                                  lastPacketInBlock);

<span class="keyword">}</span>

return payloadLen;
</code></pre><p>  }</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://linrunzhang.github.io/2015/11/26/hadoop-读写分析/" data-id="cihftfwfk0004fuyn51xt8ndu" class="article-share-link" data-share="baidu" data-title="hadoop 读写分析">分享到</a>
      

      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2015/11/26/hadoop-heatbeats/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">hadoop heatbeats</div>
    </a>
  
</nav>

  
</article>

</section>
      
      <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop-deep-learning/">hadoop deep learning</a><span class="tag-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/hadoop-deep-learning/" style="font-size: 10px;">hadoop deep learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/11/26/hadoop-读写分析/">hadoop 读写分析</a>
          </li>
        
          <li>
            <a href="/2015/11/26/hadoop-heatbeats/">hadoop heatbeats</a>
          </li>
        
          <li>
            <a href="/2015/11/26/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="http://linrunzhang.github.io" target="_blank">作者</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 <a href="http://linrunzhang.github.io" target="_blank">linrunzhang<br></a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="返回顶部"><img src="/img/scrollup.png"/></a>
</div>

<!-- totop end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>
  function SetShareData(cmd, config) {
    if (shareDataTitle && shareDataUrl) {
      config.bdText = shareDataTitle;
      config.bdUrl = shareDataUrl;
    }
    return config;
  }
  window._bd_share_config={
    "common":{onBeforeClick: SetShareData},
    "share":{"bdCustomStyle":"/css/bdshare.css"}
  };
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="http://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script src="/js/script.js" type="text/javascript"></script>

</div>
</body>
</html>
